<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Dada2 | Worked Bioninformatics, Statistics, and Machine Learning Examples</title>
  <meta name="description" content="Code, notes, lectures, and research that should be helpful for learning purposes." />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Dada2 | Worked Bioninformatics, Statistics, and Machine Learning Examples" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://sw1.github.io/teaching/" />
  
  <meta property="og:description" content="Code, notes, lectures, and research that should be helpful for learning purposes." />
  <meta name="github-repo" content="sw1/teaching" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Dada2 | Worked Bioninformatics, Statistics, and Machine Learning Examples" />
  
  <meta name="twitter:description" content="Code, notes, lectures, and research that should be helpful for learning purposes." />
  

<meta name="author" content="Stephen Woloszynek" />


<meta name="date" content="2020-02-24" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="phyloseq.html"/>
<link rel="next" href="qiime.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li>Data Science Examples</li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="dynprog.html"><a href="dynprog.html"><i class="fa fa-check"></i><b>2</b> Dynamic Programming</a><ul>
<li class="chapter" data-level="2.1" data-path="dynprog.html"><a href="dynprog.html#introduction-1"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="dynprog.html"><a href="dynprog.html#rod-cutting"><i class="fa fa-check"></i><b>2.2</b> Rod cutting</a></li>
<li class="chapter" data-level="2.3" data-path="dynprog.html"><a href="dynprog.html#fibonacci-rabbits"><i class="fa fa-check"></i><b>2.3</b> Fibonacci rabbits</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="align.html"><a href="align.html"><i class="fa fa-check"></i><b>3</b> Alignment</a><ul>
<li class="chapter" data-level="3.1" data-path="align.html"><a href="align.html#longest-common-subsequence"><i class="fa fa-check"></i><b>3.1</b> Longest Common Subsequence</a></li>
<li class="chapter" data-level="3.2" data-path="align.html"><a href="align.html#global-alignment"><i class="fa fa-check"></i><b>3.2</b> Global Alignment</a></li>
<li class="chapter" data-level="3.3" data-path="align.html"><a href="align.html#local-alignment"><i class="fa fa-check"></i><b>3.3</b> Local Alignment</a></li>
<li class="chapter" data-level="3.4" data-path="align.html"><a href="align.html#local-alignment-homework"><i class="fa fa-check"></i><b>3.4</b> Local Alignment: Homework</a></li>
<li class="chapter" data-level="3.5" data-path="align.html"><a href="align.html#global-alignment-code-r"><i class="fa fa-check"></i><b>3.5</b> Global Alignment Code (R)</a></li>
<li class="chapter" data-level="3.6" data-path="align.html"><a href="align.html#global-alignment-code-python"><i class="fa fa-check"></i><b>3.6</b> Global Alignment Code (Python)</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="alignalg.html"><a href="alignalg.html"><i class="fa fa-check"></i><b>4</b> Alignment Algorithms</a><ul>
<li class="chapter" data-level="4.1" data-path="alignalg.html"><a href="alignalg.html#longest-common-subsequence-1"><i class="fa fa-check"></i><b>4.1</b> Longest Common Subsequence</a></li>
<li class="chapter" data-level="4.2" data-path="alignalg.html"><a href="alignalg.html#global-alignment-r"><i class="fa fa-check"></i><b>4.2</b> Global Alignment (R)</a></li>
<li class="chapter" data-level="4.3" data-path="alignalg.html"><a href="alignalg.html#global-alignment-python"><i class="fa fa-check"></i><b>4.3</b> Global Alignment (Python)</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="biocond.html"><a href="biocond.html"><i class="fa fa-check"></i><b>5</b> Bioconductor</a><ul>
<li class="chapter" data-level="5.0.1" data-path="biocond.html"><a href="biocond.html#loading-fasta-files"><i class="fa fa-check"></i><b>5.0.1</b> Loading FASTA Files</a></li>
<li class="chapter" data-level="5.0.2" data-path="biocond.html"><a href="biocond.html#creating-sequence-sets"><i class="fa fa-check"></i><b>5.0.2</b> Creating Sequence Sets</a></li>
<li class="chapter" data-level="5.0.3" data-path="biocond.html"><a href="biocond.html#sample-metadata"><i class="fa fa-check"></i><b>5.0.3</b> Sample Metadata</a></li>
<li class="chapter" data-level="5.1" data-path="biocond.html"><a href="biocond.html#creating-gc-functions"><i class="fa fa-check"></i><b>5.1</b> Creating GC Functions</a></li>
<li class="chapter" data-level="5.2" data-path="biocond.html"><a href="biocond.html#ncbi-esearch"><i class="fa fa-check"></i><b>5.2</b> NCBI ESearch</a></li>
<li class="chapter" data-level="5.3" data-path="biocond.html"><a href="biocond.html#cds"><i class="fa fa-check"></i><b>5.3</b> CDS</a></li>
<li class="chapter" data-level="5.4" data-path="biocond.html"><a href="biocond.html#whole-genomes"><i class="fa fa-check"></i><b>5.4</b> Whole Genomes</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="sra.html"><a href="sra.html"><i class="fa fa-check"></i><b>6</b> Retrieving Projects</a><ul>
<li class="chapter" data-level="6.0.1" data-path="sra.html"><a href="sra.html#fastq-dump-for-paired-end-reads"><i class="fa fa-check"></i><b>6.0.1</b> Fastq Dump for Paired End Reads</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="phyloseq.html"><a href="phyloseq.html"><i class="fa fa-check"></i><b>7</b> Phyloseq</a></li>
<li class="chapter" data-level="8" data-path="dada.html"><a href="dada.html"><i class="fa fa-check"></i><b>8</b> Dada2</a><ul>
<li class="chapter" data-level="8.1" data-path="dada.html"><a href="dada.html#fastq-prep"><i class="fa fa-check"></i><b>8.1</b> FASTQ Prep</a></li>
<li class="chapter" data-level="8.2" data-path="dada.html"><a href="dada.html#otu-picking"><i class="fa fa-check"></i><b>8.2</b> OTU Picking</a></li>
<li class="chapter" data-level="8.3" data-path="dada.html"><a href="dada.html#running-dada2-on-proteus"><i class="fa fa-check"></i><b>8.3</b> Running Dada2 on Proteus</a><ul>
<li class="chapter" data-level="8.3.1" data-path="dada.html"><a href="dada.html#method-1-using-namegrp-shared-r-library"><i class="fa fa-check"></i><b>8.3.1</b> Method 1: Using nameGrp Shared R Library</a></li>
<li class="chapter" data-level="8.3.2" data-path="dada.html"><a href="dada.html#method-2-creating-a-local-library"><i class="fa fa-check"></i><b>8.3.2</b> Method 2: Creating a Local Library</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="qiime.html"><a href="qiime.html"><i class="fa fa-check"></i><b>9</b> Qiime</a><ul>
<li class="chapter" data-level="9.1" data-path="qiime.html"><a href="qiime.html#otu-picking-1"><i class="fa fa-check"></i><b>9.1</b> OTU Picking</a></li>
<li class="chapter" data-level="9.2" data-path="qiime.html"><a href="qiime.html#summarizing-our-results"><i class="fa fa-check"></i><b>9.2</b> Summarizing Our Results</a></li>
<li class="chapter" data-level="9.3" data-path="qiime.html"><a href="qiime.html#loading-qiime-results-into-phyloseq"><i class="fa fa-check"></i><b>9.3</b> Loading QIIME Results into Phyloseq</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="multcomp.html"><a href="multcomp.html"><i class="fa fa-check"></i><b>10</b> Multiple Comparisons</a><ul>
<li class="chapter" data-level="10.1" data-path="multcomp.html"><a href="multcomp.html#hypothesis-testing-and-power"><i class="fa fa-check"></i><b>10.1</b> Hypothesis Testing and Power</a></li>
<li class="chapter" data-level="10.2" data-path="multcomp.html"><a href="multcomp.html#multiple-comparisons"><i class="fa fa-check"></i><b>10.2</b> Multiple Comparisons</a><ul>
<li class="chapter" data-level="10.2.1" data-path="multcomp.html"><a href="multcomp.html#bonferroni"><i class="fa fa-check"></i><b>10.2.1</b> Bonferroni</a></li>
<li class="chapter" data-level="10.2.2" data-path="multcomp.html"><a href="multcomp.html#false-discovery-rate"><i class="fa fa-check"></i><b>10.2.2</b> False Discovery Rate</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="lasso.html"><a href="lasso.html"><i class="fa fa-check"></i><b>11</b> Lasso</a><ul>
<li class="chapter" data-level="11.1" data-path="lasso.html"><a href="lasso.html#big-data-and-feature-selection"><i class="fa fa-check"></i><b>11.1</b> Big Data and Feature Selection</a></li>
<li class="chapter" data-level="11.2" data-path="lasso.html"><a href="lasso.html#lasso-regression"><i class="fa fa-check"></i><b>11.2</b> Lasso Regression</a></li>
<li class="chapter" data-level="11.3" data-path="lasso.html"><a href="lasso.html#multivariate-lasso-regression"><i class="fa fa-check"></i><b>11.3</b> Multivariate Lasso Regression</a></li>
<li class="chapter" data-level="11.4" data-path="lasso.html"><a href="lasso.html#parallel-coordinate-descent"><i class="fa fa-check"></i><b>11.4</b> Parallel Coordinate Descent</a></li>
<li class="chapter" data-level="11.5" data-path="lasso.html"><a href="lasso.html#simulations"><i class="fa fa-check"></i><b>11.5</b> Simulations</a><ul>
<li class="chapter" data-level="11.5.1" data-path="lasso.html"><a href="lasso.html#times-1000-matrix-5-target-coefficients"><i class="fa fa-check"></i><b>11.5.1</b> <span class="math inline">\(50 \times 1000\)</span> Matrix | 5 Target Coefficients</a></li>
<li class="chapter" data-level="11.5.2" data-path="lasso.html"><a href="lasso.html#times-10000-matrix-5-target-coefficients"><i class="fa fa-check"></i><b>11.5.2</b> <span class="math inline">\(50 \times 10000\)</span> Matrix | 5 Target Coefficients</a></li>
<li class="chapter" data-level="11.5.3" data-path="lasso.html"><a href="lasso.html#times-10000-matrix-5-target-coefficients-1"><i class="fa fa-check"></i><b>11.5.3</b> <span class="math inline">\(200 \times 10000\)</span> Matrix | 5 Target Coefficients</a></li>
<li class="chapter" data-level="11.5.4" data-path="lasso.html"><a href="lasso.html#times-10000-matrix-15-target-coefficients"><i class="fa fa-check"></i><b>11.5.4</b> <span class="math inline">\(50 \times 10000\)</span> Matrix | 15 Target Coefficients</a></li>
<li class="chapter" data-level="11.5.5" data-path="lasso.html"><a href="lasso.html#times-10000-matrix-30-target-coefficients"><i class="fa fa-check"></i><b>11.5.5</b> <span class="math inline">\(50 \times 10000\)</span> Matrix | 30 Target Coefficients</a></li>
<li class="chapter" data-level="11.5.6" data-path="lasso.html"><a href="lasso.html#scaling-the-coeficients"><i class="fa fa-check"></i><b>11.5.6</b> Scaling the coeficients</a></li>
<li class="chapter" data-level="11.5.7" data-path="lasso.html"><a href="lasso.html#comparison"><i class="fa fa-check"></i><b>11.5.7</b> Comparison</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="lasso.html"><a href="lasso.html#conclusion"><i class="fa fa-check"></i><b>11.6</b> Conclusion</a></li>
<li class="chapter" data-level="11.7" data-path="lasso.html"><a href="lasso.html#code-lasso"><i class="fa fa-check"></i><b>11.7</b> Code: Lasso</a></li>
<li class="chapter" data-level="11.8" data-path="lasso.html"><a href="lasso.html#code-lasso-via-cyclic-gradient-descent"><i class="fa fa-check"></i><b>11.8</b> Code: Lasso via cyclic gradient descent</a></li>
<li class="chapter" data-level="11.9" data-path="lasso.html"><a href="lasso.html#code-parallel-lasso"><i class="fa fa-check"></i><b>11.9</b> Code: Parallel lasso</a></li>
<li class="chapter" data-level="11.10" data-path="lasso.html"><a href="lasso.html#references"><i class="fa fa-check"></i><b>11.10</b> References</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="tm.html"><a href="tm.html"><i class="fa fa-check"></i><b>12</b> Topic Models</a><ul>
<li class="chapter" data-level="12.1" data-path="tm.html"><a href="tm.html#variational-inference"><i class="fa fa-check"></i><b>12.1</b> Variational Inference</a><ul>
<li class="chapter" data-level="12.1.1" data-path="tm.html"><a href="tm.html#evidence-lower-bound-elbo"><i class="fa fa-check"></i><b>12.1.1</b> Evidence Lower Bound (ELBO)</a></li>
<li class="chapter" data-level="12.1.2" data-path="tm.html"><a href="tm.html#elbo-and-kl-divergence"><i class="fa fa-check"></i><b>12.1.2</b> ELBO and KL Divergence</a></li>
<li class="chapter" data-level="12.1.3" data-path="tm.html"><a href="tm.html#mean-field-method"><i class="fa fa-check"></i><b>12.1.3</b> Mean Field Method</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="tm.html"><a href="tm.html#lda"><i class="fa fa-check"></i><b>12.2</b> LDA</a><ul>
<li class="chapter" data-level="12.2.1" data-path="tm.html"><a href="tm.html#expectation-of-pthetaalpha"><i class="fa fa-check"></i><b>12.2.1</b> Expectation of p(<span class="math inline">\(\theta|\alpha)\)</span></a></li>
<li class="chapter" data-level="12.2.2" data-path="tm.html"><a href="tm.html#expectation-of-pztheta"><i class="fa fa-check"></i><b>12.2.2</b> Expectation of p(<span class="math inline">\(z|\theta)\)</span></a></li>
<li class="chapter" data-level="12.2.3" data-path="tm.html"><a href="tm.html#expectation-of-pwzbeta"><i class="fa fa-check"></i><b>12.2.3</b> Expectation of p(<span class="math inline">\(w|z,\beta)\)</span></a></li>
<li class="chapter" data-level="12.2.4" data-path="tm.html"><a href="tm.html#entropy-of-gamma-and-phi"><i class="fa fa-check"></i><b>12.2.4</b> Entropy of <span class="math inline">\(\gamma\)</span> and <span class="math inline">\(\phi\)</span></a></li>
<li class="chapter" data-level="12.2.5" data-path="tm.html"><a href="tm.html#complete-objective-function"><i class="fa fa-check"></i><b>12.2.5</b> Complete Objective Function</a></li>
<li class="chapter" data-level="12.2.6" data-path="tm.html"><a href="tm.html#parameter-optimization"><i class="fa fa-check"></i><b>12.2.6</b> Parameter Optimization</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="tm.html"><a href="tm.html#supervised-lda"><i class="fa fa-check"></i><b>12.3</b> Supervised LDA</a><ul>
<li class="chapter" data-level="12.3.1" data-path="tm.html"><a href="tm.html#expectations-of-pthetaalpha-pztheta-and-pwzbeta"><i class="fa fa-check"></i><b>12.3.1</b> Expectations of <span class="math inline">\(p(\theta|\alpha)\)</span>, <span class="math inline">\(p(z|\theta)\)</span>, and <span class="math inline">\(p(w|z,\beta)\)</span></a></li>
<li class="chapter" data-level="12.3.2" data-path="tm.html"><a href="tm.html#expectation-of-pyzetasigma2"><i class="fa fa-check"></i><b>12.3.2</b> Expectation of <span class="math inline">\(p(y|z,\eta,\sigma^2)\)</span></a></li>
<li class="chapter" data-level="12.3.3" data-path="tm.html"><a href="tm.html#entropy-of-gamma-and-phi-1"><i class="fa fa-check"></i><b>12.3.3</b> Entropy of <span class="math inline">\(\gamma\)</span> and <span class="math inline">\(\phi\)</span></a></li>
<li class="chapter" data-level="12.3.4" data-path="tm.html"><a href="tm.html#complete-objective-function-1"><i class="fa fa-check"></i><b>12.3.4</b> Complete Objective Function</a></li>
<li class="chapter" data-level="12.3.5" data-path="tm.html"><a href="tm.html#parameter-optimization-1"><i class="fa fa-check"></i><b>12.3.5</b> Parameter Optimization</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="tm.html"><a href="tm.html#the-correlated-topic-model"><i class="fa fa-check"></i><b>12.4</b> The Correlated Topic Model</a><ul>
<li class="chapter" data-level="12.4.1" data-path="tm.html"><a href="tm.html#multinomial-distribution-in-exponential-form"><i class="fa fa-check"></i><b>12.4.1</b> Multinomial Distribution in Exponential Form</a></li>
<li class="chapter" data-level="12.4.2" data-path="tm.html"><a href="tm.html#variational-em"><i class="fa fa-check"></i><b>12.4.2</b> Variational EM</a></li>
<li class="chapter" data-level="12.4.3" data-path="tm.html"><a href="tm.html#expectation-of-pwzbeta-1"><i class="fa fa-check"></i><b>12.4.3</b> Expectation of <span class="math inline">\(p(w|z,\beta)\)</span></a></li>
<li class="chapter" data-level="12.4.4" data-path="tm.html"><a href="tm.html#expectation-of-pzeta"><i class="fa fa-check"></i><b>12.4.4</b> Expectation of <span class="math inline">\(p(z|\eta)\)</span></a></li>
<li class="chapter" data-level="12.4.5" data-path="tm.html"><a href="tm.html#expectation-of-petamusigma"><i class="fa fa-check"></i><b>12.4.5</b> Expectation of <span class="math inline">\(p(\eta|\mu,\sigma)\)</span></a></li>
<li class="chapter" data-level="12.4.6" data-path="tm.html"><a href="tm.html#entropy-of-lambda-nu-and-phi"><i class="fa fa-check"></i><b>12.4.6</b> Entropy of <span class="math inline">\(\lambda\)</span>, <span class="math inline">\(\nu\)</span>, and <span class="math inline">\(\phi\)</span></a></li>
<li class="chapter" data-level="12.4.7" data-path="tm.html"><a href="tm.html#complete-objective-function-2"><i class="fa fa-check"></i><b>12.4.7</b> Complete Objective Function</a></li>
<li class="chapter" data-level="12.4.8" data-path="tm.html"><a href="tm.html#parameter-optimization-2"><i class="fa fa-check"></i><b>12.4.8</b> Parameter Optimization</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="tm.html"><a href="tm.html#dirichlet-distribution"><i class="fa fa-check"></i><b>12.5</b> Dirichlet Distribution</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="ml.html"><a href="ml.html"><i class="fa fa-check"></i><b>13</b> Machine Learning</a><ul>
<li class="chapter" data-level="13.1" data-path="ml.html"><a href="ml.html#cross-valdiation"><i class="fa fa-check"></i><b>13.1</b> Cross Valdiation</a><ul>
<li class="chapter" data-level="13.1.1" data-path="ml.html"><a href="ml.html#loocv"><i class="fa fa-check"></i><b>13.1.1</b> LOOCV</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="ml.html"><a href="ml.html#naive-bayes"><i class="fa fa-check"></i><b>13.2</b> Naive Bayes</a></li>
<li class="chapter" data-level="13.3" data-path="ml.html"><a href="ml.html#svm"><i class="fa fa-check"></i><b>13.3</b> SVM</a><ul>
<li class="chapter" data-level="13.3.1" data-path="ml.html"><a href="ml.html#manual-rbf-kernal"><i class="fa fa-check"></i><b>13.3.1</b> Manual rbf kernal</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="ml.html"><a href="ml.html#k-means"><i class="fa fa-check"></i><b>13.4</b> K-means</a></li>
<li class="chapter" data-level="13.5" data-path="ml.html"><a href="ml.html#gaussian-mixtures"><i class="fa fa-check"></i><b>13.5</b> Gaussian Mixtures</a></li>
<li class="chapter" data-level="13.6" data-path="ml.html"><a href="ml.html#pca"><i class="fa fa-check"></i><b>13.6</b> PCA</a></li>
<li class="chapter" data-level="13.7" data-path="ml.html"><a href="ml.html#viterbi-algorithm"><i class="fa fa-check"></i><b>13.7</b> Viterbi Algorithm</a></li>
<li class="chapter" data-level="13.8" data-path="ml.html"><a href="ml.html#gradient-descent"><i class="fa fa-check"></i><b>13.8</b> Gradient Descent</a><ul>
<li class="chapter" data-level="13.8.1" data-path="ml.html"><a href="ml.html#linear-regression"><i class="fa fa-check"></i><b>13.8.1</b> Linear Regression</a></li>
<li class="chapter" data-level="13.8.2" data-path="ml.html"><a href="ml.html#logistic-regression"><i class="fa fa-check"></i><b>13.8.2</b> Logistic Regression</a></li>
<li class="chapter" data-level="13.8.3" data-path="ml.html"><a href="ml.html#softmax-regression"><i class="fa fa-check"></i><b>13.8.3</b> Softmax regression</a></li>
</ul></li>
<li class="chapter" data-level="13.9" data-path="ml.html"><a href="ml.html#nonparametric-bayesian-processes"><i class="fa fa-check"></i><b>13.9</b> Nonparametric Bayesian Processes</a><ul>
<li class="chapter" data-level="13.9.1" data-path="ml.html"><a href="ml.html#chinese-restaurant"><i class="fa fa-check"></i><b>13.9.1</b> Chinese Restaurant</a></li>
<li class="chapter" data-level="13.9.2" data-path="ml.html"><a href="ml.html#polyas-urn"><i class="fa fa-check"></i><b>13.9.2</b> Polyas Urn</a></li>
<li class="chapter" data-level="13.9.3" data-path="ml.html"><a href="ml.html#stick-breaking"><i class="fa fa-check"></i><b>13.9.3</b> Stick Breaking</a></li>
</ul></li>
<li class="chapter" data-level="13.10" data-path="ml.html"><a href="ml.html#iteratively-reweighted-least-squares"><i class="fa fa-check"></i><b>13.10</b> Iteratively Reweighted Least Squares</a></li>
<li class="chapter" data-level="13.11" data-path="ml.html"><a href="ml.html#neural-network"><i class="fa fa-check"></i><b>13.11</b> Neural Network</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/sw1/" target="blank">Published by Stephen Woloszynek</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Worked Bioninformatics, Statistics, and Machine Learning Examples</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="dada" class="section level1">
<h1><span class="header-section-number">Chapter 8</span> Dada2</h1>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(dada2)
<span class="kw">library</span>(gridExtra)
<span class="kw">library</span>(DECIPHER)
<span class="kw">library</span>(ape)
<span class="kw">library</span>(phangorn)
<span class="kw">library</span>(phyloseq)</code></pre></div>
<p>First we need to use some qiime functions via the command line, so we’ll save them as variable names.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">validate_mapping_file &lt;-<span class="st"> &#39;/data/sw1/anaconda3/envs/qiime1/bin/validate_mapping_file.py&#39;</span>
split_libraries_fastq &lt;-<span class="st"> &#39;/data/sw1/anaconda3/envs/qiime1/bin/split_libraries_fastq.py&#39;</span>
split_sequence_file_on_sample_ids &lt;-<span class="st"> &#39;/data/sw1/anaconda3/envs/qiime1/bin/split_sequence_file_on_sample_ids.py&#39;</span></code></pre></div>
<div id="fastq-prep" class="section level2">
<h2><span class="header-section-number">8.1</span> FASTQ Prep</h2>
<p>We’re going to use the same data as we did with QIIME. Dada2 requires individual fastq files for each sample, so we’ll split our single fastq file using a few QIIME commands.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_dir &lt;-<span class="st"> &#39;data/data_moving_pictures&#39;</span>

MAP &lt;-<span class="st"> </span><span class="kw">read_delim</span>(<span class="kw">file.path</span>(data_dir,<span class="st">&#39;map.tsv&#39;</span>),<span class="st">&#39;</span><span class="ch">\t</span><span class="st">&#39;</span>)</code></pre></div>
<pre><code>## Parsed with column specification:
## cols(
##   `#SampleID` = col_character(),
##   BarcodeSequence = col_character(),
##   LinkerPrimerSequence = col_character(),
##   SampleType = col_character(),
##   Year = col_double(),
##   Month = col_double(),
##   Day = col_double(),
##   Subject = col_double(),
##   ReportedAntibioticUsage = col_character(),
##   DaysSinceExperimentStart = col_double(),
##   Description = col_character()
## )</code></pre>
<p>Note that now we are forcing the split libraries command to also return a demultiplexed fastq file. We going to also add a bunch of arguments to ensure that QIIME does <em>no</em> filtering. We want to deal with that using dada2.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">system2</span>(split_libraries_fastq,<span class="dt">args=</span><span class="kw">c</span>(<span class="st">&#39;-o&#39;</span>,<span class="kw">file.path</span>(data_dir,<span class="st">&#39;fastq_out_3&#39;</span>),
                                     <span class="st">&#39;-i&#39;</span>,<span class="kw">file.path</span>(data_dir,<span class="st">&#39;forward_reads.fastq.gz&#39;</span>),
                                     <span class="st">&#39;-b&#39;</span>,<span class="kw">file.path</span>(data_dir,<span class="st">&#39;barcodes.fastq.gz&#39;</span>),
                                     <span class="st">&#39;-m&#39;</span>,<span class="kw">file.path</span>(data_dir,<span class="st">&#39;map.tsv&#39;</span>),
                                     <span class="st">&#39;-r&#39;</span>,<span class="st">&#39;999&#39;</span>,
                                     <span class="st">&#39;-n&#39;</span>,<span class="st">&#39;999&#39;</span>,
                                     <span class="st">&#39;-q&#39;</span>,<span class="st">&#39;0&#39;</span>,
                                     <span class="st">&#39;-p&#39;</span>,<span class="st">&#39;0.0001&#39;</span>,
                                     <span class="st">&#39;--store_demultiplexed_fastq&#39;</span>))</code></pre></div>
<p>Next, we’ll split these fastq file into separate files for each sample:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">system2</span>(split_sequence_file_on_sample_ids,<span class="dt">args=</span><span class="kw">c</span>(<span class="st">&#39;-i&#39;</span>,<span class="kw">file.path</span>(data_dir,<span class="st">&#39;fastq_out_3&#39;</span>,<span class="st">&#39;seqs.fastq&#39;</span>),
                                                 <span class="st">&#39;-o&#39;</span>,<span class="kw">file.path</span>(data_dir,<span class="st">&#39;fastq_out_3&#39;</span>,<span class="st">&#39;sequences&#39;</span>),
                                                 <span class="st">&#39;--file_type&#39;</span>,<span class="st">&#39;fastq&#39;</span>))</code></pre></div>
</div>
<div id="otu-picking" class="section level2">
<h2><span class="header-section-number">8.2</span> OTU Picking</h2>
<p>We’re now going to run through the dada2 workflow. Dada2 is a <em>reference free</em> method, so this is analogous to de novo OTU picking had we used QIIME. Still, we can cluster our resulting count table into OTUs using a reference database; hence, we can compare our results.</p>
<p>Dada2 captures metagenomic variation by exploiting illumina sequencing errors. Briefly, everything is based on an error model (a Poisson distribution). A given read is defined as a <em>sample</em> sequence and is compared to all other reads. The model calculates the probability these reads were generated from the sample sequence given the error model – that is, the probability that these reads resulted from independent sequencing errors that were generated based on given transition probabilities and quality scores. If a set of reads are too abundant to be explained by this error model, then they are separated into their own partition. The game is to continuously partition the reads until each partition is consistent with the error model, allowing us to separate true biological variation from the variation solely due to sequencing error. At this point, the abundance of reads within a partition can be calculated, giving us an abundance table. We can then compare the sequences associated with a given partition to a reference database to assign taxonomy.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fqs &lt;-<span class="st"> </span><span class="kw">list.files</span>(<span class="kw">file.path</span>(data_dir,<span class="st">&#39;fastq_out_3&#39;</span>,<span class="st">&#39;sequences&#39;</span>),<span class="dt">full.names=</span><span class="ot">TRUE</span>)</code></pre></div>
<p>The first thing we’ll do is plot the quality scores as a function of base position. If you recall the definition of Q from the QIIME tutorial, this should make sense to you, and it should also help you appriciate setting those parameters for quality filtering before.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sample_idx &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">length</span>(fqs),<span class="dv">5</span>)
for (i in sample_idx) <span class="kw">print</span>(<span class="kw">plotQualityProfile</span>(fqs[i]))</code></pre></div>
<pre><code>## Scale for &#39;y&#39; is already present. Adding another scale for &#39;y&#39;, which will
## replace the existing scale.
## Scale for &#39;y&#39; is already present. Adding another scale for &#39;y&#39;, which will
## replace the existing scale.</code></pre>
<p><img src="07_dada2_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<pre><code>## Scale for &#39;y&#39; is already present. Adding another scale for &#39;y&#39;, which will
## replace the existing scale.</code></pre>
<p><img src="07_dada2_files/figure-html/unnamed-chunk-8-2.png" width="672" /></p>
<pre><code>## Scale for &#39;y&#39; is already present. Adding another scale for &#39;y&#39;, which will
## replace the existing scale.</code></pre>
<p><img src="07_dada2_files/figure-html/unnamed-chunk-8-3.png" width="672" /></p>
<pre><code>## Scale for &#39;y&#39; is already present. Adding another scale for &#39;y&#39;, which will
## replace the existing scale.</code></pre>
<p><img src="07_dada2_files/figure-html/unnamed-chunk-8-4.png" width="672" /><img src="07_dada2_files/figure-html/unnamed-chunk-8-5.png" width="672" /></p>
<p>Per the Holmes group, illumina datasets often have errors in the first 10 base positions. Also, given the plots above, there seems to be a drop in quality towards the end of each read. Hence, we’ll trim our reads such that we keep bases 10 through 130.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fqs_filt &lt;-<span class="st"> </span><span class="kw">gsub</span>(<span class="st">&#39;sequences&#39;</span>,<span class="st">&#39;filtered&#39;</span>,fqs)
<span class="kw">dir.create</span>(<span class="kw">gsub</span>(<span class="st">&#39;(filtered).*&#39;</span>,<span class="st">&#39;</span><span class="ch">\\</span><span class="st">1&#39;</span>,fqs_filt[<span class="dv">1</span>]),<span class="dt">showWarnings=</span><span class="ot">FALSE</span>)
for (i in <span class="kw">seq_along</span>(fqs)){
  <span class="kw">fastqFilter</span>(fqs[i],fqs_filt[i],
              <span class="dt">trimLeft=</span><span class="dv">10</span>, <span class="dt">truncLen=</span><span class="dv">130</span>,
              <span class="dt">maxN=</span><span class="dv">0</span>, <span class="dt">maxEE=</span><span class="dv">2</span>, <span class="dt">truncQ=</span><span class="dv">2</span>,
              <span class="dt">compress=</span><span class="ot">TRUE</span>)
}</code></pre></div>
<p>The following command performs dereplication, returning a set of unique sequences and abundances from our set of fastq files.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">derep &lt;-<span class="st"> </span><span class="kw">derepFastq</span>(fqs_filt)
<span class="kw">names</span>(derep) &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="kw">strsplit</span>(<span class="kw">basename</span>(fqs_filt), <span class="st">&quot;_&quot;</span>), <span class="st">`</span><span class="dt">[</span><span class="st">`</span>, <span class="dv">1</span>)</code></pre></div>
<p>Dada2’s error model depends on the fact that there are 16x41 transition probabilities, but if these values are unknown, we can simply estimate them from the data. However, estimating the error rates to parameterize the model is costly, so it’s recommended to do this on a subset of the data, and then use these parameter estimates for the complete dataset:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dd_err &lt;-<span class="st"> </span><span class="kw">dada</span>(derep[<span class="dv">1</span>:<span class="dv">10</span>], <span class="dt">err=</span><span class="ot">NULL</span>, <span class="dt">selfConsist=</span><span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## Initializing error rates to maximum possible estimate.
## selfConsist step 1 ..........
##    selfConsist step 2
##    selfConsist step 3
##    selfConsist step 4
##    selfConsist step 5
##    selfConsist step 6
##    selfConsist step 7
## Convergence after  7  rounds.</code></pre>
<p>We can visualize the error estimates. This shows the frequency of each base transition as a function of quality score.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plotErrors</span>(dd_err,<span class="dt">err_in=</span><span class="ot">TRUE</span>,<span class="dt">nominalQ=</span><span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## Warning: Transformation introduced infinite values in continuous y-axis

## Warning: Transformation introduced infinite values in continuous y-axis</code></pre>
<p><img src="07_dada2_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>We’ll now fit the full error model, using the estimated error rates from our subset of data. This step can be parallelized using the multihread argument. We’re also going to pool across samples, since this improves the detection of variants that are rare in a specific sample but less rare overall, but at a computational cost.</p>
<p>Note that we can pass a lot of arguments into this function that control the error model. As briefly described above, the game is to partition these sequences until each partition is consistent with being generated soley by illumina and amplification error variation, and not due to biological variation. A p-value is calculated to test the sequences that form new partitions, with signififcant p-values at a given threshold leading to new parittions.</p>
<p>Now, say we had a problem where rare sequence variants were of most interest. It would then make sense to use a less conservative significance threshold, leading to <em>more</em> significant p-values, more partitions, and hence more rare variants. We can do this by increasing the <strong>OMEGA_A</strong> value from its default value of <span class="math inline">\(1\times10^{-40}\)</span>. We’ll fit a second model and change the threshold to <span class="math inline">\(1\times10^{-20}\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dd &lt;-<span class="st"> </span><span class="kw">dada</span>(derep, <span class="dt">err=</span>dd_err[[<span class="dv">1</span>]]$err_out, <span class="dt">pool=</span><span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## 34 samples were pooled: 109854 reads in 18034 unique sequences.</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dd_rare &lt;-<span class="st"> </span><span class="kw">dada</span>(derep, <span class="dt">err=</span>dd_err[[<span class="dv">1</span>]]$err_out, <span class="dt">pool=</span><span class="ot">TRUE</span>, <span class="dt">OMEGA_A=</span><span class="fl">1e-20</span>)</code></pre></div>
<pre><code>## 34 samples were pooled: 109854 reads in 18034 unique sequences.</code></pre>
<p>Finally, we’ll make our sequence table.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">seqtab_all &lt;-<span class="st"> </span><span class="kw">makeSequenceTable</span>(dd)
seqtab_all_rare &lt;-<span class="st"> </span><span class="kw">makeSequenceTable</span>(dd_rare)</code></pre></div>
<p>And then we’ll remove chimeras. This function compares sequences against one another, and removes sequences that can be generated by joining two abundant sequences.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">seqtab &lt;-<span class="st"> </span><span class="kw">removeBimeraDenovo</span>(seqtab_all)
seqtab_rare &lt;-<span class="st"> </span><span class="kw">removeBimeraDenovo</span>(seqtab_all_rare)</code></pre></div>
<p>First, note the difference in dimensions; there are more sequences in the rare table:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ncol</span>(seqtab)</code></pre></div>
<pre><code>## [1] 662</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ncol</span>(seqtab_rare)</code></pre></div>
<pre><code>## [1] 817</code></pre>
<p>Also note that despite now having a sequence abundance table that is similar in form to the OTU table we generated in QIIME, our ‘taxonomic variants’ are unique sequences and <em>not</em> OTUs:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">seqtab[<span class="dv">1</span>:<span class="dv">5</span>,<span class="dv">1</span>:<span class="dv">5</span>]</code></pre></div>
<pre><code>##              CCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGAGCGTAGATGGATGTTTAAGTCAGTTGTGAAAGTTTGCGGCTCAACCGTAAAATTGCAGTTGATACTGGATATCTTGAGTGCAGTT
## L1S105.fastq                                                                                                                     1769
## L1S140.fastq                                                                                                                        8
## L1S208.fastq                                                                                                                       11
## L1S257.fastq                                                                                                                        6
## L1S281.fastq                                                                                                                        4
##              GCGAGCGTTAATCGGAATTACTGGGCGTAAAGCGAGCGCAGACGGTTACTTAAGCAGGATGTGAAATCCCCGGGCTCAACCTGGGAACTGCGTTCTGAACTGGGTGACTAGAGTGTGTCA
## L1S105.fastq                                                                                                                        5
## L1S140.fastq                                                                                                                        1
## L1S208.fastq                                                                                                                        0
## L1S257.fastq                                                                                                                        0
## L1S281.fastq                                                                                                                        0
##              CCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGAGCGTAGATGGATGTTTAAGTCAGTTGTGAAAGTTTGCGGCTCAACCGTAAAATTGCAGTTGATACTGGATGTCTTGAGTGCAGTT
## L1S105.fastq                                                                                                                        8
## L1S140.fastq                                                                                                                     1531
## L1S208.fastq                                                                                                                     1552
## L1S257.fastq                                                                                                                      870
## L1S281.fastq                                                                                                                     1196
##              GCGAGCGTTAATCGGAATAACTGGGCGTAAAGGGCACGCAGGCGGTGACTTAAGTGAGGTGTGAAAGCCCCGGGCTTAACCTGGGAATTGCATTTCATACTGGGTCGCTAGAGTACTTTA
## L1S105.fastq                                                                                                                        0
## L1S140.fastq                                                                                                                        0
## L1S208.fastq                                                                                                                        5
## L1S257.fastq                                                                                                                        0
## L1S281.fastq                                                                                                                        0
##              CCGAGCGTTGTCCGGATTTATTGGGCGTAAAGCGAGCGCAGGCGGTTAGATAAGTCTGAAGTTAAAGGCTGTGGCTTAACCATAGTACGCTTTGGAAACTGTTTAACTTGAGTGCAAGAG
## L1S105.fastq                                                                                                                        1
## L1S140.fastq                                                                                                                        0
## L1S208.fastq                                                                                                                        2
## L1S257.fastq                                                                                                                        0
## L1S281.fastq                                                                                                                        0</code></pre>
<p>If we want to assign taxonomy from a reference database to these sequences, we can use the following command that applies a naive Bayes classifer to compare our sequences to classified sequences in a training set. First, we’ll use a GreenGenes training set:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ref_fasta &lt;-<span class="st"> &#39;data/data_stability/references/gg_13_8_train_set_97.fa.gz&#39;</span>
taxtab_gg &lt;-<span class="st"> </span><span class="kw">assignTaxonomy</span>(seqtab, <span class="dt">refFasta=</span>ref_fasta)
<span class="kw">colnames</span>(taxtab_gg) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Kingdom&quot;</span>, <span class="st">&quot;Phylum&quot;</span>, <span class="st">&quot;Class&quot;</span>, <span class="st">&quot;Order&quot;</span>, <span class="st">&quot;Family&quot;</span>, <span class="st">&quot;Genus&quot;</span>, <span class="st">&quot;Species&quot;</span>)</code></pre></div>
<p>Now, instead, we can try a Silva training set. Note that Silva does not give species level assignments</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ref_fasta &lt;-<span class="st"> &#39;data/data_stability/references/silva_nr_v123_train_set.fa.gz&#39;</span>
taxtab_silva &lt;-<span class="st"> </span><span class="kw">assignTaxonomy</span>(seqtab, <span class="dt">refFasta=</span>ref_fasta)
<span class="kw">colnames</span>(taxtab_silva) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Kingdom&quot;</span>, <span class="st">&quot;Phylum&quot;</span>, <span class="st">&quot;Class&quot;</span>, <span class="st">&quot;Order&quot;</span>, <span class="st">&quot;Family&quot;</span>, <span class="st">&quot;Genus&quot;</span>)</code></pre></div>
<p>If we want species level assignments, we can do the following.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ref_fasta &lt;-<span class="st"> &#39;data/data_stability/references/rdp_species_assignment_14.fa.gz&#39;</span>
sptab_silva &lt;-<span class="st"> </span><span class="kw">assignSpecies</span>(seqtab, <span class="dt">refFasta=</span>ref_fasta, <span class="dt">allowMultiple=</span><span class="ot">FALSE</span>, <span class="dt">verbose=</span><span class="ot">TRUE</span>)</code></pre></div>
<p>Next, we might want to build a phylogenetic tree. First, we perform a multiple sequence alignment:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">seqs &lt;-<span class="st"> </span><span class="kw">getSequences</span>(seqtab)
<span class="kw">names</span>(seqs) &lt;-<span class="st"> </span>seqs
alignment &lt;-<span class="st"> </span><span class="kw">AlignSeqs</span>(<span class="kw">DNAStringSet</span>(seqs), <span class="dt">anchor=</span><span class="ot">NA</span>)</code></pre></div>
<p>Then, we’ll build a tree, specifically, a maximum likelihood tree from a NJ tree.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">phang_align &lt;-<span class="st"> </span><span class="kw">phyDat</span>(<span class="kw">as.matrix</span>(alignment), <span class="dt">type=</span><span class="st">&quot;DNA&quot;</span>)
dm &lt;-<span class="st"> </span><span class="kw">dist.ml</span>(phang_align)
treeNJ &lt;-<span class="st"> </span><span class="kw">NJ</span>(dm) <span class="co"># Note, tip order != sequence order</span>
fit =<span class="st"> </span><span class="kw">pml</span>(treeNJ, <span class="dt">data=</span>phang_align)

fit_gtr &lt;-<span class="st"> </span><span class="kw">update</span>(fit, <span class="dt">k=</span><span class="dv">4</span>, <span class="dt">inv=</span><span class="fl">0.2</span>)
fit_gtr &lt;-<span class="st"> </span><span class="kw">optim.pml</span>(fit_gtr, <span class="dt">model=</span><span class="st">&quot;GTR&quot;</span>, <span class="dt">optInv=</span><span class="ot">TRUE</span>, <span class="dt">optGamma=</span><span class="ot">TRUE</span>,
                      <span class="dt">rearrangement =</span> <span class="st">&quot;stochastic&quot;</span>, <span class="dt">control =</span> <span class="kw">pml.control</span>(<span class="dt">trace =</span> <span class="dv">0</span>))</code></pre></div>
<p>And finally, we can build our phyloseq object for our GreenGenes table:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">TREE &lt;-<span class="st"> </span><span class="kw">phy_tree</span>(fit_gtr)

META &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(MAP)
<span class="kw">rownames</span>(META) &lt;-<span class="st"> </span>META$<span class="st">`</span><span class="dt">#SampleID</span><span class="st">`</span>

OTU &lt;-<span class="st"> </span>seqtab
<span class="kw">rownames</span>(OTU) &lt;-<span class="st"> </span><span class="kw">gsub</span>(<span class="st">&#39;</span><span class="ch">\\</span><span class="st">.fastq&#39;</span>,<span class="st">&#39;&#39;</span>,<span class="kw">rownames</span>(OTU))
OTU &lt;-<span class="st"> </span>OTU[<span class="kw">rownames</span>(META),]
OTU &lt;-<span class="st"> </span><span class="kw">otu_table</span>(OTU,<span class="dt">taxa_are_rows=</span><span class="ot">FALSE</span>)
  
META &lt;-<span class="st"> </span><span class="kw">sample_data</span>(META)

TAXA &lt;-<span class="st"> </span>taxtab_gg[<span class="kw">colnames</span>(OTU),]
TAXA &lt;-<span class="st"> </span><span class="kw">tax_table</span>(TAXA)

PS &lt;-<span class="st"> </span><span class="kw">phyloseq</span>(OTU,TAXA,META,TREE)</code></pre></div>
</div>
<div id="running-dada2-on-proteus" class="section level2">
<h2><span class="header-section-number">8.3</span> Running Dada2 on Proteus</h2>
<p>Now let’s redo the analysis above, but on a cluster. I’ll explain below how to run dada2 via two ways. The first will involve simply using packages installed in a shared group folder. The second will cover installing dada2 in a local folder. If you lack access to the shared folder, or, if for some reason it no longer exists, go to method 2.</p>
<div id="method-1-using-namegrp-shared-r-library" class="section level3">
<h3><span class="header-section-number">8.3.1</span> Method 1: Using nameGrp Shared R Library</h3>
<p>First, we’ll create a bash script that runs some QIIME commands to do the demultiplexing and splitting, and then runs the dada anlysis. We’ll assume that the moving pictures data is in your home directory. As before, the folder should contain three files: (1) the reads, (2) the barcodes, and (3) the mapping file.</p>
<p>We’ll name the script <strong>prep_sub.sh</strong>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#!/bin/bash</span>
<span class="co">#$ -S /bin/bash</span>
<span class="co">#$ -cwd</span>
<span class="co">#$ -j y</span>
<span class="co">#$ -M user_name@email.edu</span>
<span class="co">#$ -l h_rt=01:00:00</span>
<span class="co">#$ -P namePrj</span>
<span class="co">#$ -l mem_free=12G</span>
<span class="co">#$ -l h_vmem=16G</span>
<span class="co">#$ -q all.q</span>

. /etc/profile.d/modules.sh
module load shared
module load proteus
module load sge/univa
module load gcc/<span class="fl">4.8.1</span>
module load qiime/gcc/<span class="dv">64</span>/<span class="fl">1.9.1</span>

export ref_seqs=<span class="er">/</span>mnt/HA/opt/qiime/gcc/<span class="dv">64</span>/<span class="fl">1.9.1</span>/lib/python2<span class="fl">.7</span>/site-packages/qiime_default_reference/gg_13_8_otus/rep_set/97_otus.fasta
export ref_tax=<span class="er">/</span>mnt/HA/opt/qiime/gcc/<span class="dv">64</span>/<span class="fl">1.9.1</span>/lib/python2<span class="fl">.7</span>/site-packages/qiime_default_reference/gg_13_8_otus/taxonomy/97_otu_taxonomy.txt

data_dir=<span class="er">/</span>home/user_name/dirname/dada2/moving_pictures
work_dir=<span class="er">/</span>scratch/user_name/moving_pictures

mkdir -p $work_dir

cp $data_dir/<span class="er">*</span><span class="st"> </span><span class="er">$</span>work_dir

out_dir=<span class="er">$</span>work_dir/fastq_out
seqs=<span class="er">$</span>work_dir/forward_reads.fastq.gz
bc=<span class="er">$</span>work_dir/barcodes.fastq.gz
map=<span class="er">$</span>work_dir/map.tsv

split_libraries_fastq.py -o $out_dir -i $seqs -b $bc -m $map -r <span class="dv">999</span> -n <span class="dv">999</span> -q <span class="dv">0</span> -p <span class="fl">0.0001</span> --store_demultiplexed_fastq
split_sequence_file_on_sample_ids.py -i $out_dir/seqs.fastq -o $out_dir/sequences --file_type fastq

mv $out_dir/sequences $data_dir
rm -r $work_dir/<span class="er">*</span>
<span class="st">  </span>
exit <span class="dv">0</span></code></pre></div>
<p>This gives us our demultiplexed, split sequences. Now, we’ll make a dada2 R script that performs the actual analysis. We’ll call this <strong>dada.R</strong>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(dada2)

scratch_path &lt;-<span class="st"> &#39;/scratch/user_name/moving_pictures&#39;</span>
ref_fasta &lt;-<span class="st"> </span><span class="kw">file.path</span>(scratch_path,<span class="st">&#39;silva_nr_v123_train_set.fa.gz&#39;</span>)
fq_dir &lt;-<span class="st"> </span><span class="kw">file.path</span>(scratch_path,<span class="st">&#39;sequences&#39;</span>)
fqs &lt;-<span class="st"> </span><span class="kw">list.files</span>(fq_dir,<span class="dt">full.names=</span><span class="ot">TRUE</span>)

fqs_filt &lt;-<span class="st"> </span><span class="kw">gsub</span>(<span class="st">&#39;sequences&#39;</span>,<span class="st">&#39;filtered&#39;</span>,fqs)
<span class="kw">dir.create</span>(<span class="kw">gsub</span>(<span class="st">&#39;(filtered).*&#39;</span>,<span class="st">&#39;</span><span class="ch">\\</span><span class="st">1&#39;</span>,fqs_filt[<span class="dv">1</span>]),<span class="dt">showWarnings=</span><span class="ot">FALSE</span>)
for (i in <span class="kw">seq_along</span>(fqs)){
  <span class="kw">fastqFilter</span>(fqs[i],fqs_filt[i],
              <span class="dt">trimLeft=</span><span class="dv">10</span>, <span class="dt">truncLen=</span><span class="dv">130</span>,
              <span class="dt">maxN=</span><span class="dv">0</span>, <span class="dt">maxEE=</span><span class="dv">2</span>, <span class="dt">truncQ=</span><span class="dv">2</span>,
              <span class="dt">compress=</span><span class="ot">TRUE</span>)
}

derep &lt;-<span class="st"> </span><span class="kw">derepFastq</span>(fqs_filt)
<span class="kw">names</span>(derep) &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="kw">strsplit</span>(<span class="kw">basename</span>(fqs_filt), <span class="st">&quot;_&quot;</span>), <span class="st">`</span><span class="dt">[</span><span class="st">`</span>, <span class="dv">1</span>)

dd_err &lt;-<span class="st"> </span><span class="kw">dada</span>(derep[<span class="dv">1</span>:<span class="dv">10</span>],<span class="dt">err=</span><span class="ot">NULL</span>,<span class="dt">selfConsist=</span><span class="ot">TRUE</span>, <span class="dt">multithread=</span><span class="ot">TRUE</span>,<span class="dt">VERBOSE=</span><span class="ot">TRUE</span>)

dd &lt;-<span class="st"> </span><span class="kw">dada</span>(derep, <span class="dt">err=</span>dd_err[[<span class="dv">1</span>]]$err_out, <span class="dt">pool=</span><span class="ot">TRUE</span>, <span class="dt">multithread=</span><span class="ot">TRUE</span>,<span class="dt">VERBOSE=</span><span class="ot">TRUE</span>)

seqtab_all &lt;-<span class="st"> </span><span class="kw">makeSequenceTable</span>(dd)

seqtab &lt;-<span class="st"> </span><span class="kw">removeBimeraDenovo</span>(seqtab_all,<span class="dt">tableMethod=</span><span class="st">&#39;pooled&#39;</span>,<span class="dt">verbose=</span><span class="ot">TRUE</span>, <span class="dt">multithread=</span><span class="ot">TRUE</span>)

taxtab_silva &lt;-<span class="st"> </span><span class="kw">assignTaxonomy</span>(seqtab,<span class="dt">refFasta=</span>ref_fasta,<span class="dt">verbose=</span><span class="ot">TRUE</span>)
<span class="kw">colnames</span>(taxtab_silva) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Kingdom&quot;</span>, <span class="st">&quot;Phylum&quot;</span>, <span class="st">&quot;Class&quot;</span>, <span class="st">&quot;Order&quot;</span>, <span class="st">&quot;Family&quot;</span>, <span class="st">&quot;Genus&quot;</span>)

<span class="kw">saveRDS</span>(seqtab,<span class="kw">file.path</span>(scratch_path,<span class="st">&#39;seqtab.rds&#39;</span>))
<span class="kw">saveRDS</span>(taxtab_silva,<span class="kw">file.path</span>(scratch_path,<span class="st">&#39;taxtab.rds&#39;</span>))</code></pre></div>
<p>Finally, we’ll create the submission script. <strong>Note the following change that allows you to use the packages in the shared folder.</strong> In this submission script, immediately after you load your modules, you must add the line:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">export R_LIBS=<span class="er">/</span>mnt/HA/groups/nameGrp/r_libs</code></pre></div>
<p>This gives us the following submission script:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#!/bin/bash</span>
<span class="co">#$ -S /bin/bash</span>
<span class="co">#$ -cwd</span>
<span class="co">#$ -j y</span>
<span class="co">#$ -M user_name@email.edu</span>
<span class="co">#$ -l h_rt=01:00:00</span>
<span class="co">#$ -P namePrj</span>
<span class="co">#$ -pe shm 16</span>
<span class="co">#$ -l mem_free=12G</span>
<span class="co">#$ -l h_vmem=16G</span>
<span class="co">#$ -q all.q</span>

. /etc/profile.d/modules.sh
module load shared
module load proteus
module load sge/univa
module load gcc/<span class="fl">4.8.1</span>

export R_LIBS=<span class="er">/</span>mnt/HA/groups/nameGrp/r_libs

data_dir=<span class="er">/</span>home/user_name/dirname/dada2
work_dir=<span class="er">/</span>scratch/user_name/moving_pictures

mkdir -p $work_dir

cp -r $data_dir/moving_pictures/sequences $work_dir
cp $data_dir/dada.R $work_dir
cp ~<span class="er">/</span>references/silva_nr_v123_train_set.fa.gz $work_dir

R CMD BATCH $work_dir/dada.R

mv $work_dir/<span class="er">*</span>.Rout $data_dir
mv $work_dir/<span class="er">*</span>.rds $data_dir
rm -rf $work_dir

exit <span class="dv">0</span></code></pre></div>
</div>
<div id="method-2-creating-a-local-library" class="section level3">
<h3><span class="header-section-number">8.3.2</span> Method 2: Creating a Local Library</h3>
<p>We first need to make two scripts. One will be an R package script that installs our packages into a personal library folder. The other will run this script, but it will first make said folder and also unload any preloaded gcc modules that may cause conflicts during pacakge installation.</p>
<p>First, make sure you’re in your home directory. We’ll now make the R package installer script. We’ll call it <strong>install_r_pkgs.R</strong>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">MYLIB &lt;-<span class="st"> </span><span class="kw">Sys.getenv</span>(<span class="st">&#39;R_LIBS_USER&#39;</span>)

<span class="kw">source</span>(<span class="st">&#39;https://bioconductor.org/biocLite.R&#39;</span>)
<span class="kw">biocLite</span>(<span class="st">&#39;dada2&#39;</span>,<span class="dt">lib=</span>MYLIB)</code></pre></div>
<p>Next, we’ll make the bash script that runs this, which we’ll call <strong>run_install_r_pkgs.sh</strong>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#!/bin/bash</span>

module unload gcc

Rscript -e <span class="st">&quot;dir.create(Sys.getenv(&#39;R_LIBS_USER&#39;),showWarnings=FALSE,recursive=TRUE)&quot;</span>
R CMD BATCH install_r_pkgs.R</code></pre></div>
<p>Finally, we’ll run the bash script by entering the following at the command line (this will take a few minutes to run):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">chmod +x run_install_r_pkgs.sh
./run_install_r_pkgs.sh</code></pre></div>
<p>You should now have a R folder in your home directory, and if you navigate through it, you should see a dada folder. To ensure your installation worked, in your home directly, type <strong>R</strong> to enter the R environment. Then, run <strong>library(dada2)</strong>. Assuming everything loads correctly, we can proceed to submitting a job.</p>
<p><strong>Note that in the submission script, you must remove the line where we changed the R_LIBS path</strong>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">export R_LIBS=<span class="er">/</span>mnt/HA/groups/nameGrp/r_libs</code></pre></div>
<p>which gives us the following submission script:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#!/bin/bash</span>
<span class="co">#$ -S /bin/bash</span>
<span class="co">#$ -cwd</span>
<span class="co">#$ -j y</span>
<span class="co">#$ -M user_name@email.edu</span>
<span class="co">#$ -l h_rt=01:00:00</span>
<span class="co">#$ -P namePrj</span>
<span class="co">#$ -pe shm 16</span>
<span class="co">#$ -l mem_free=12G</span>
<span class="co">#$ -l h_vmem=16G</span>
<span class="co">#$ -q all.q</span>

. /etc/profile.d/modules.sh
module load shared
module load proteus
module load sge/univa
module load gcc/<span class="fl">4.8.1</span>

data_dir=<span class="er">/</span>home/user_name/dirname/dada2
work_dir=<span class="er">/</span>scratch/user_name/moving_pictures

mkdir -p $work_dir

cp -r $data_dir/moving_pictures/sequences $work_dir
cp $data_dir/dada.R $work_dir
cp ~<span class="er">/</span>references/silva_nr_v123_train_set.fa.gz $work_dir

R CMD BATCH $work_dir/dada.R

mv $work_dir/<span class="er">*</span>.Rout $data_dir
mv $work_dir/<span class="er">*</span>.rds $data_dir
rm -rf $work_dir

exit <span class="dv">0</span></code></pre></div>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="phyloseq.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="qiime.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bioinformatics.pdf"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
