<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 13 Machine Learning | Worked Bioninformatics, Statistics, and Machine Learning Examples</title>
  <meta name="description" content="Code, notes, lectures, and research that should be helpful for learning purposes." />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 13 Machine Learning | Worked Bioninformatics, Statistics, and Machine Learning Examples" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://sw1.github.io/teaching/" />
  
  <meta property="og:description" content="Code, notes, lectures, and research that should be helpful for learning purposes." />
  <meta name="github-repo" content="sw1/teaching" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 13 Machine Learning | Worked Bioninformatics, Statistics, and Machine Learning Examples" />
  
  <meta name="twitter:description" content="Code, notes, lectures, and research that should be helpful for learning purposes." />
  

<meta name="author" content="Stephen Woloszynek" />


<meta name="date" content="2020-02-24" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="tm.html"/>

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li>Data Science Examples</li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="dynprog.html"><a href="dynprog.html"><i class="fa fa-check"></i><b>2</b> Dynamic Programming</a><ul>
<li class="chapter" data-level="2.1" data-path="dynprog.html"><a href="dynprog.html#introduction-1"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="dynprog.html"><a href="dynprog.html#rod-cutting"><i class="fa fa-check"></i><b>2.2</b> Rod cutting</a></li>
<li class="chapter" data-level="2.3" data-path="dynprog.html"><a href="dynprog.html#fibonacci-rabbits"><i class="fa fa-check"></i><b>2.3</b> Fibonacci rabbits</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="align.html"><a href="align.html"><i class="fa fa-check"></i><b>3</b> Alignment</a><ul>
<li class="chapter" data-level="3.1" data-path="align.html"><a href="align.html#longest-common-subsequence"><i class="fa fa-check"></i><b>3.1</b> Longest Common Subsequence</a></li>
<li class="chapter" data-level="3.2" data-path="align.html"><a href="align.html#global-alignment"><i class="fa fa-check"></i><b>3.2</b> Global Alignment</a></li>
<li class="chapter" data-level="3.3" data-path="align.html"><a href="align.html#local-alignment"><i class="fa fa-check"></i><b>3.3</b> Local Alignment</a></li>
<li class="chapter" data-level="3.4" data-path="align.html"><a href="align.html#local-alignment-homework"><i class="fa fa-check"></i><b>3.4</b> Local Alignment: Homework</a></li>
<li class="chapter" data-level="3.5" data-path="align.html"><a href="align.html#global-alignment-code-r"><i class="fa fa-check"></i><b>3.5</b> Global Alignment Code (R)</a></li>
<li class="chapter" data-level="3.6" data-path="align.html"><a href="align.html#global-alignment-code-python"><i class="fa fa-check"></i><b>3.6</b> Global Alignment Code (Python)</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="alignalg.html"><a href="alignalg.html"><i class="fa fa-check"></i><b>4</b> Alignment Algorithms</a><ul>
<li class="chapter" data-level="4.1" data-path="alignalg.html"><a href="alignalg.html#longest-common-subsequence-1"><i class="fa fa-check"></i><b>4.1</b> Longest Common Subsequence</a></li>
<li class="chapter" data-level="4.2" data-path="alignalg.html"><a href="alignalg.html#global-alignment-r"><i class="fa fa-check"></i><b>4.2</b> Global Alignment (R)</a></li>
<li class="chapter" data-level="4.3" data-path="alignalg.html"><a href="alignalg.html#global-alignment-python"><i class="fa fa-check"></i><b>4.3</b> Global Alignment (Python)</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="biocond.html"><a href="biocond.html"><i class="fa fa-check"></i><b>5</b> Bioconductor</a><ul>
<li class="chapter" data-level="5.0.1" data-path="biocond.html"><a href="biocond.html#loading-fasta-files"><i class="fa fa-check"></i><b>5.0.1</b> Loading FASTA Files</a></li>
<li class="chapter" data-level="5.0.2" data-path="biocond.html"><a href="biocond.html#creating-sequence-sets"><i class="fa fa-check"></i><b>5.0.2</b> Creating Sequence Sets</a></li>
<li class="chapter" data-level="5.0.3" data-path="biocond.html"><a href="biocond.html#sample-metadata"><i class="fa fa-check"></i><b>5.0.3</b> Sample Metadata</a></li>
<li class="chapter" data-level="5.1" data-path="biocond.html"><a href="biocond.html#creating-gc-functions"><i class="fa fa-check"></i><b>5.1</b> Creating GC Functions</a></li>
<li class="chapter" data-level="5.2" data-path="biocond.html"><a href="biocond.html#ncbi-esearch"><i class="fa fa-check"></i><b>5.2</b> NCBI ESearch</a></li>
<li class="chapter" data-level="5.3" data-path="biocond.html"><a href="biocond.html#cds"><i class="fa fa-check"></i><b>5.3</b> CDS</a></li>
<li class="chapter" data-level="5.4" data-path="biocond.html"><a href="biocond.html#whole-genomes"><i class="fa fa-check"></i><b>5.4</b> Whole Genomes</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="sra.html"><a href="sra.html"><i class="fa fa-check"></i><b>6</b> Retrieving Projects</a><ul>
<li class="chapter" data-level="6.0.1" data-path="sra.html"><a href="sra.html#fastq-dump-for-paired-end-reads"><i class="fa fa-check"></i><b>6.0.1</b> Fastq Dump for Paired End Reads</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="phyloseq.html"><a href="phyloseq.html"><i class="fa fa-check"></i><b>7</b> Phyloseq</a></li>
<li class="chapter" data-level="8" data-path="dada.html"><a href="dada.html"><i class="fa fa-check"></i><b>8</b> Dada2</a><ul>
<li class="chapter" data-level="8.1" data-path="dada.html"><a href="dada.html#fastq-prep"><i class="fa fa-check"></i><b>8.1</b> FASTQ Prep</a></li>
<li class="chapter" data-level="8.2" data-path="dada.html"><a href="dada.html#otu-picking"><i class="fa fa-check"></i><b>8.2</b> OTU Picking</a></li>
<li class="chapter" data-level="8.3" data-path="dada.html"><a href="dada.html#running-dada2-on-proteus"><i class="fa fa-check"></i><b>8.3</b> Running Dada2 on Proteus</a><ul>
<li class="chapter" data-level="8.3.1" data-path="dada.html"><a href="dada.html#method-1-using-namegrp-shared-r-library"><i class="fa fa-check"></i><b>8.3.1</b> Method 1: Using nameGrp Shared R Library</a></li>
<li class="chapter" data-level="8.3.2" data-path="dada.html"><a href="dada.html#method-2-creating-a-local-library"><i class="fa fa-check"></i><b>8.3.2</b> Method 2: Creating a Local Library</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="qiime.html"><a href="qiime.html"><i class="fa fa-check"></i><b>9</b> Qiime</a><ul>
<li class="chapter" data-level="9.1" data-path="qiime.html"><a href="qiime.html#otu-picking-1"><i class="fa fa-check"></i><b>9.1</b> OTU Picking</a></li>
<li class="chapter" data-level="9.2" data-path="qiime.html"><a href="qiime.html#summarizing-our-results"><i class="fa fa-check"></i><b>9.2</b> Summarizing Our Results</a></li>
<li class="chapter" data-level="9.3" data-path="qiime.html"><a href="qiime.html#loading-qiime-results-into-phyloseq"><i class="fa fa-check"></i><b>9.3</b> Loading QIIME Results into Phyloseq</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="multcomp.html"><a href="multcomp.html"><i class="fa fa-check"></i><b>10</b> Multiple Comparisons</a><ul>
<li class="chapter" data-level="10.1" data-path="multcomp.html"><a href="multcomp.html#hypothesis-testing-and-power"><i class="fa fa-check"></i><b>10.1</b> Hypothesis Testing and Power</a></li>
<li class="chapter" data-level="10.2" data-path="multcomp.html"><a href="multcomp.html#multiple-comparisons"><i class="fa fa-check"></i><b>10.2</b> Multiple Comparisons</a><ul>
<li class="chapter" data-level="10.2.1" data-path="multcomp.html"><a href="multcomp.html#bonferroni"><i class="fa fa-check"></i><b>10.2.1</b> Bonferroni</a></li>
<li class="chapter" data-level="10.2.2" data-path="multcomp.html"><a href="multcomp.html#false-discovery-rate"><i class="fa fa-check"></i><b>10.2.2</b> False Discovery Rate</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="lasso.html"><a href="lasso.html"><i class="fa fa-check"></i><b>11</b> Lasso</a><ul>
<li class="chapter" data-level="11.1" data-path="lasso.html"><a href="lasso.html#big-data-and-feature-selection"><i class="fa fa-check"></i><b>11.1</b> Big Data and Feature Selection</a></li>
<li class="chapter" data-level="11.2" data-path="lasso.html"><a href="lasso.html#lasso-regression"><i class="fa fa-check"></i><b>11.2</b> Lasso Regression</a></li>
<li class="chapter" data-level="11.3" data-path="lasso.html"><a href="lasso.html#multivariate-lasso-regression"><i class="fa fa-check"></i><b>11.3</b> Multivariate Lasso Regression</a></li>
<li class="chapter" data-level="11.4" data-path="lasso.html"><a href="lasso.html#parallel-coordinate-descent"><i class="fa fa-check"></i><b>11.4</b> Parallel Coordinate Descent</a></li>
<li class="chapter" data-level="11.5" data-path="lasso.html"><a href="lasso.html#simulations"><i class="fa fa-check"></i><b>11.5</b> Simulations</a><ul>
<li class="chapter" data-level="11.5.1" data-path="lasso.html"><a href="lasso.html#times-1000-matrix-5-target-coefficients"><i class="fa fa-check"></i><b>11.5.1</b> <span class="math inline">\(50 \times 1000\)</span> Matrix | 5 Target Coefficients</a></li>
<li class="chapter" data-level="11.5.2" data-path="lasso.html"><a href="lasso.html#times-10000-matrix-5-target-coefficients"><i class="fa fa-check"></i><b>11.5.2</b> <span class="math inline">\(50 \times 10000\)</span> Matrix | 5 Target Coefficients</a></li>
<li class="chapter" data-level="11.5.3" data-path="lasso.html"><a href="lasso.html#times-10000-matrix-5-target-coefficients-1"><i class="fa fa-check"></i><b>11.5.3</b> <span class="math inline">\(200 \times 10000\)</span> Matrix | 5 Target Coefficients</a></li>
<li class="chapter" data-level="11.5.4" data-path="lasso.html"><a href="lasso.html#times-10000-matrix-15-target-coefficients"><i class="fa fa-check"></i><b>11.5.4</b> <span class="math inline">\(50 \times 10000\)</span> Matrix | 15 Target Coefficients</a></li>
<li class="chapter" data-level="11.5.5" data-path="lasso.html"><a href="lasso.html#times-10000-matrix-30-target-coefficients"><i class="fa fa-check"></i><b>11.5.5</b> <span class="math inline">\(50 \times 10000\)</span> Matrix | 30 Target Coefficients</a></li>
<li class="chapter" data-level="11.5.6" data-path="lasso.html"><a href="lasso.html#scaling-the-coeficients"><i class="fa fa-check"></i><b>11.5.6</b> Scaling the coeficients</a></li>
<li class="chapter" data-level="11.5.7" data-path="lasso.html"><a href="lasso.html#comparison"><i class="fa fa-check"></i><b>11.5.7</b> Comparison</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="lasso.html"><a href="lasso.html#conclusion"><i class="fa fa-check"></i><b>11.6</b> Conclusion</a></li>
<li class="chapter" data-level="11.7" data-path="lasso.html"><a href="lasso.html#code-lasso"><i class="fa fa-check"></i><b>11.7</b> Code: Lasso</a></li>
<li class="chapter" data-level="11.8" data-path="lasso.html"><a href="lasso.html#code-lasso-via-cyclic-gradient-descent"><i class="fa fa-check"></i><b>11.8</b> Code: Lasso via cyclic gradient descent</a></li>
<li class="chapter" data-level="11.9" data-path="lasso.html"><a href="lasso.html#code-parallel-lasso"><i class="fa fa-check"></i><b>11.9</b> Code: Parallel lasso</a></li>
<li class="chapter" data-level="11.10" data-path="lasso.html"><a href="lasso.html#references"><i class="fa fa-check"></i><b>11.10</b> References</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="tm.html"><a href="tm.html"><i class="fa fa-check"></i><b>12</b> Topic Models</a><ul>
<li class="chapter" data-level="12.1" data-path="tm.html"><a href="tm.html#variational-inference"><i class="fa fa-check"></i><b>12.1</b> Variational Inference</a><ul>
<li class="chapter" data-level="12.1.1" data-path="tm.html"><a href="tm.html#evidence-lower-bound-elbo"><i class="fa fa-check"></i><b>12.1.1</b> Evidence Lower Bound (ELBO)</a></li>
<li class="chapter" data-level="12.1.2" data-path="tm.html"><a href="tm.html#elbo-and-kl-divergence"><i class="fa fa-check"></i><b>12.1.2</b> ELBO and KL Divergence</a></li>
<li class="chapter" data-level="12.1.3" data-path="tm.html"><a href="tm.html#mean-field-method"><i class="fa fa-check"></i><b>12.1.3</b> Mean Field Method</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="tm.html"><a href="tm.html#lda"><i class="fa fa-check"></i><b>12.2</b> LDA</a><ul>
<li class="chapter" data-level="12.2.1" data-path="tm.html"><a href="tm.html#expectation-of-pthetaalpha"><i class="fa fa-check"></i><b>12.2.1</b> Expectation of p(<span class="math inline">\(\theta|\alpha)\)</span></a></li>
<li class="chapter" data-level="12.2.2" data-path="tm.html"><a href="tm.html#expectation-of-pztheta"><i class="fa fa-check"></i><b>12.2.2</b> Expectation of p(<span class="math inline">\(z|\theta)\)</span></a></li>
<li class="chapter" data-level="12.2.3" data-path="tm.html"><a href="tm.html#expectation-of-pwzbeta"><i class="fa fa-check"></i><b>12.2.3</b> Expectation of p(<span class="math inline">\(w|z,\beta)\)</span></a></li>
<li class="chapter" data-level="12.2.4" data-path="tm.html"><a href="tm.html#entropy-of-gamma-and-phi"><i class="fa fa-check"></i><b>12.2.4</b> Entropy of <span class="math inline">\(\gamma\)</span> and <span class="math inline">\(\phi\)</span></a></li>
<li class="chapter" data-level="12.2.5" data-path="tm.html"><a href="tm.html#complete-objective-function"><i class="fa fa-check"></i><b>12.2.5</b> Complete Objective Function</a></li>
<li class="chapter" data-level="12.2.6" data-path="tm.html"><a href="tm.html#parameter-optimization"><i class="fa fa-check"></i><b>12.2.6</b> Parameter Optimization</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="tm.html"><a href="tm.html#supervised-lda"><i class="fa fa-check"></i><b>12.3</b> Supervised LDA</a><ul>
<li class="chapter" data-level="12.3.1" data-path="tm.html"><a href="tm.html#expectations-of-pthetaalpha-pztheta-and-pwzbeta"><i class="fa fa-check"></i><b>12.3.1</b> Expectations of <span class="math inline">\(p(\theta|\alpha)\)</span>, <span class="math inline">\(p(z|\theta)\)</span>, and <span class="math inline">\(p(w|z,\beta)\)</span></a></li>
<li class="chapter" data-level="12.3.2" data-path="tm.html"><a href="tm.html#expectation-of-pyzetasigma2"><i class="fa fa-check"></i><b>12.3.2</b> Expectation of <span class="math inline">\(p(y|z,\eta,\sigma^2)\)</span></a></li>
<li class="chapter" data-level="12.3.3" data-path="tm.html"><a href="tm.html#entropy-of-gamma-and-phi-1"><i class="fa fa-check"></i><b>12.3.3</b> Entropy of <span class="math inline">\(\gamma\)</span> and <span class="math inline">\(\phi\)</span></a></li>
<li class="chapter" data-level="12.3.4" data-path="tm.html"><a href="tm.html#complete-objective-function-1"><i class="fa fa-check"></i><b>12.3.4</b> Complete Objective Function</a></li>
<li class="chapter" data-level="12.3.5" data-path="tm.html"><a href="tm.html#parameter-optimization-1"><i class="fa fa-check"></i><b>12.3.5</b> Parameter Optimization</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="tm.html"><a href="tm.html#the-correlated-topic-model"><i class="fa fa-check"></i><b>12.4</b> The Correlated Topic Model</a><ul>
<li class="chapter" data-level="12.4.1" data-path="tm.html"><a href="tm.html#multinomial-distribution-in-exponential-form"><i class="fa fa-check"></i><b>12.4.1</b> Multinomial Distribution in Exponential Form</a></li>
<li class="chapter" data-level="12.4.2" data-path="tm.html"><a href="tm.html#variational-em"><i class="fa fa-check"></i><b>12.4.2</b> Variational EM</a></li>
<li class="chapter" data-level="12.4.3" data-path="tm.html"><a href="tm.html#expectation-of-pwzbeta-1"><i class="fa fa-check"></i><b>12.4.3</b> Expectation of <span class="math inline">\(p(w|z,\beta)\)</span></a></li>
<li class="chapter" data-level="12.4.4" data-path="tm.html"><a href="tm.html#expectation-of-pzeta"><i class="fa fa-check"></i><b>12.4.4</b> Expectation of <span class="math inline">\(p(z|\eta)\)</span></a></li>
<li class="chapter" data-level="12.4.5" data-path="tm.html"><a href="tm.html#expectation-of-petamusigma"><i class="fa fa-check"></i><b>12.4.5</b> Expectation of <span class="math inline">\(p(\eta|\mu,\sigma)\)</span></a></li>
<li class="chapter" data-level="12.4.6" data-path="tm.html"><a href="tm.html#entropy-of-lambda-nu-and-phi"><i class="fa fa-check"></i><b>12.4.6</b> Entropy of <span class="math inline">\(\lambda\)</span>, <span class="math inline">\(\nu\)</span>, and <span class="math inline">\(\phi\)</span></a></li>
<li class="chapter" data-level="12.4.7" data-path="tm.html"><a href="tm.html#complete-objective-function-2"><i class="fa fa-check"></i><b>12.4.7</b> Complete Objective Function</a></li>
<li class="chapter" data-level="12.4.8" data-path="tm.html"><a href="tm.html#parameter-optimization-2"><i class="fa fa-check"></i><b>12.4.8</b> Parameter Optimization</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="tm.html"><a href="tm.html#dirichlet-distribution"><i class="fa fa-check"></i><b>12.5</b> Dirichlet Distribution</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="ml.html"><a href="ml.html"><i class="fa fa-check"></i><b>13</b> Machine Learning</a><ul>
<li class="chapter" data-level="13.1" data-path="ml.html"><a href="ml.html#cross-valdiation"><i class="fa fa-check"></i><b>13.1</b> Cross Valdiation</a><ul>
<li class="chapter" data-level="13.1.1" data-path="ml.html"><a href="ml.html#loocv"><i class="fa fa-check"></i><b>13.1.1</b> LOOCV</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="ml.html"><a href="ml.html#naive-bayes"><i class="fa fa-check"></i><b>13.2</b> Naive Bayes</a></li>
<li class="chapter" data-level="13.3" data-path="ml.html"><a href="ml.html#svm"><i class="fa fa-check"></i><b>13.3</b> SVM</a><ul>
<li class="chapter" data-level="13.3.1" data-path="ml.html"><a href="ml.html#manual-rbf-kernal"><i class="fa fa-check"></i><b>13.3.1</b> Manual rbf kernal</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="ml.html"><a href="ml.html#k-means"><i class="fa fa-check"></i><b>13.4</b> K-means</a></li>
<li class="chapter" data-level="13.5" data-path="ml.html"><a href="ml.html#gaussian-mixtures"><i class="fa fa-check"></i><b>13.5</b> Gaussian Mixtures</a></li>
<li class="chapter" data-level="13.6" data-path="ml.html"><a href="ml.html#pca"><i class="fa fa-check"></i><b>13.6</b> PCA</a></li>
<li class="chapter" data-level="13.7" data-path="ml.html"><a href="ml.html#viterbi-algorithm"><i class="fa fa-check"></i><b>13.7</b> Viterbi Algorithm</a></li>
<li class="chapter" data-level="13.8" data-path="ml.html"><a href="ml.html#gradient-descent"><i class="fa fa-check"></i><b>13.8</b> Gradient Descent</a><ul>
<li class="chapter" data-level="13.8.1" data-path="ml.html"><a href="ml.html#linear-regression"><i class="fa fa-check"></i><b>13.8.1</b> Linear Regression</a></li>
<li class="chapter" data-level="13.8.2" data-path="ml.html"><a href="ml.html#logistic-regression"><i class="fa fa-check"></i><b>13.8.2</b> Logistic Regression</a></li>
<li class="chapter" data-level="13.8.3" data-path="ml.html"><a href="ml.html#softmax-regression"><i class="fa fa-check"></i><b>13.8.3</b> Softmax regression</a></li>
</ul></li>
<li class="chapter" data-level="13.9" data-path="ml.html"><a href="ml.html#nonparametric-bayesian-processes"><i class="fa fa-check"></i><b>13.9</b> Nonparametric Bayesian Processes</a><ul>
<li class="chapter" data-level="13.9.1" data-path="ml.html"><a href="ml.html#chinese-restaurant"><i class="fa fa-check"></i><b>13.9.1</b> Chinese Restaurant</a></li>
<li class="chapter" data-level="13.9.2" data-path="ml.html"><a href="ml.html#polyas-urn"><i class="fa fa-check"></i><b>13.9.2</b> Polyas Urn</a></li>
<li class="chapter" data-level="13.9.3" data-path="ml.html"><a href="ml.html#stick-breaking"><i class="fa fa-check"></i><b>13.9.3</b> Stick Breaking</a></li>
</ul></li>
<li class="chapter" data-level="13.10" data-path="ml.html"><a href="ml.html#iteratively-reweighted-least-squares"><i class="fa fa-check"></i><b>13.10</b> Iteratively Reweighted Least Squares</a></li>
<li class="chapter" data-level="13.11" data-path="ml.html"><a href="ml.html#neural-network"><i class="fa fa-check"></i><b>13.11</b> Neural Network</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/sw1/" target="blank">Published by Stephen Woloszynek</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Worked Bioninformatics, Statistics, and Machine Learning Examples</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ml" class="section level1">
<h1><span class="header-section-number">Chapter 13</span> Machine Learning</h1>
<div id="cross-valdiation" class="section level2">
<h2><span class="header-section-number">13.1</span> Cross Valdiation</h2>
<p>Proof that k-fold CV has less variance around the mean than LOOCV â€“ better for k-fold CV.</p>
<div id="loocv" class="section level3">
<h3><span class="header-section-number">13.1.1</span> LOOCV</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">N =<span class="st"> </span><span class="dv">1000</span>    <span class="co"># data size</span>
p =<span class="st"> </span>.<span class="dv">10</span> <span class="co"># probability of a misclassification</span>

<span class="kw">set.seed</span>(<span class="dv">100</span>)
d1 &lt;-<span class="st"> </span><span class="kw">rbinom</span>(N,<span class="dv">1</span>,p) <span class="co"># bernoulli sampling: sample 1, check if it&#39;s a match</span>
<span class="kw">mean</span>(d1)</code></pre></div>
<pre><code>## [1] 0.113</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(d1)*(<span class="dv">1</span>-<span class="kw">mean</span>(d1))   <span class="co"># var</span></code></pre></div>
<pre><code>## [1] 0.100231</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">var</span>(d1)</code></pre></div>
<pre><code>## [1] 0.1003313</code></pre>
<p>10-fold CV</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">k =<span class="st"> </span><span class="dv">10</span>              <span class="co"># number of CV replications</span>
n =<span class="st"> </span>N/k             <span class="co"># sample size for each k from data N</span>
<span class="kw">set.seed</span>(<span class="dv">100</span>)
d2 &lt;-<span class="st"> </span><span class="kw">rbinom</span>(N,n,p)/n       <span class="co"># binomial sampling: from 1000, </span>
                    <span class="co"># sample 100, sum number that are wrong of 100, </span>
                    <span class="co"># divide by sample size to get error rate</span>
<span class="kw">mean</span>(d2)</code></pre></div>
<pre><code>## [1] 0.10191</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(k/N)*<span class="kw">mean</span>(d2)*(<span class="dv">1</span>-<span class="kw">mean</span>(d2)) <span class="co"># var</span></code></pre></div>
<pre><code>## [1] 0.0009152435</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">var</span>(d2)</code></pre></div>
<pre><code>## [1] 0.0009229749</code></pre>
<p>note that 10xCV var is &lt; LOOCV var.</p>
</div>
</div>
<div id="naive-bayes" class="section level2">
<h2><span class="header-section-number">13.2</span> Naive Bayes</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sex &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;M&quot;</span>,<span class="st">&quot;F&quot;</span>),<span class="dt">each=</span><span class="dv">4</span>)               <span class="co"># feature 1</span>
h &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">6</span>,<span class="fl">5.92</span>,<span class="fl">5.58</span>,<span class="fl">5.92</span>,<span class="dv">5</span>,<span class="fl">5.5</span>,<span class="fl">5.42</span>,<span class="fl">5.75</span>)        <span class="co"># feature 2</span>
w &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">180</span>,<span class="dv">190</span>,<span class="dv">170</span>,<span class="dv">165</span>,<span class="dv">100</span>,<span class="dv">150</span>,<span class="dv">130</span>,<span class="dv">150</span>)     <span class="co"># feature 3</span>
f &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">12</span>,<span class="dv">11</span>,<span class="dv">12</span>,<span class="dv">10</span>,<span class="dv">6</span>,<span class="dv">8</span>,<span class="dv">7</span>,<span class="dv">9</span>)             <span class="co"># feature 4</span>

df1 &lt;-<span class="st"> </span><span class="kw">data.frame</span>(sex,h,w,f)
uh &lt;-<span class="st"> </span><span class="kw">tapply</span>(df1$h,df1$sex,mean)
uf &lt;-<span class="st"> </span><span class="kw">tapply</span>(df1$f,df1$sex,mean)
uw &lt;-<span class="st"> </span><span class="kw">tapply</span>(df1$w,df1$sex,mean)
sh &lt;-<span class="st"> </span><span class="kw">tapply</span>(df1$h,df1$sex,sd)
sf &lt;-<span class="st"> </span><span class="kw">tapply</span>(df1$f,df1$sex,sd)
sw &lt;-<span class="st"> </span><span class="kw">tapply</span>(df1$w,df1$sex,sd)

new &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="st">&quot;h&quot;</span>=<span class="dv">6</span>,<span class="st">&quot;w&quot;</span>=<span class="dv">130</span>,<span class="st">&quot;f&quot;</span>=<span class="dv">8</span>)

ps &lt;-<span class="st"> </span><span class="kw">table</span>(df1$sex)/<span class="kw">length</span>(df1$sex)    <span class="co"># P(F) P(M)</span>
phgs &lt;-<span class="st"> </span><span class="kw">dnorm</span>(new$h,uh,sh)          <span class="co"># P(h|F) P(h|M)</span>
pwgs &lt;-<span class="st"> </span><span class="kw">dnorm</span>(new$w,uw,sw)          <span class="co"># P(h|F) P(h|M)</span>
pfgs &lt;-<span class="st"> </span><span class="kw">dnorm</span>(new$f,uf,sf)          <span class="co"># P(h|F) P(h|M)</span>

postf &lt;-<span class="st"> </span>ps[<span class="dv">1</span>]*phgs[<span class="dv">1</span>]*pwgs[<span class="dv">1</span>]*pfgs[<span class="dv">1</span>]  <span class="co"># P(sex|h,w,f) = P(sex)*P(h|sex)*P(w|sex)*P(f|sex)</span>
postm &lt;-<span class="st"> </span>ps[<span class="dv">2</span>]*phgs[<span class="dv">2</span>]*pwgs[<span class="dv">2</span>]*pfgs[<span class="dv">2</span>]

if (postm &gt;<span class="st"> </span>postf) <span class="st">&quot;M&quot;</span> else <span class="st">&quot;F&quot;</span></code></pre></div>
<pre><code>## [1] &quot;F&quot;</code></pre>
</div>
<div id="svm" class="section level2">
<h2><span class="header-section-number">13.3</span> SVM</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(iris)
train &lt;-<span class="st"> </span>iris
train$y &lt;-<span class="kw">ifelse</span>(train[,<span class="dv">5</span>]==<span class="st">&quot;setosa&quot;</span>, <span class="dv">1</span>, -<span class="dv">1</span>)

train &lt;-<span class="st"> </span>train[<span class="kw">order</span>(train$y, <span class="dt">decreasing=</span><span class="ot">TRUE</span>),]

X &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(train[,<span class="kw">c</span>(<span class="st">&quot;Petal.Length&quot;</span>, <span class="st">&quot;Petal.Width&quot;</span>)])
y &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(train$y)
n &lt;-<span class="st"> </span><span class="kw">dim</span>(X)[<span class="dv">1</span>]</code></pre></div>
<p><span class="math display">\[
\begin{aligned}
\max \alpha &amp;W(\alpha) = \sum{\alpha_1} - -.5 \sum{y_i y_j \alpha_i \alpha_j x_i^T x_j}\\
             &amp;\text{s.t.} \quad \alpha_i \ge 0\\
             &amp;\text{s.t.} \quad \sum_{\alpha_i * y_i} = 0
\end{aligned}
\]</span></p>
<p>is equivalent to</p>
<p><span class="math display">\[
\begin{aligned}
\min \alpha - &amp;\alpha + 0.5 \alpha^T * H * \alpha\\
             &amp;\text{s.t.} \quad \alpha \ge 0\\
             &amp;\text{s.t.} \quad A \alpha \le 0\\
             &amp;\text{where} \quad H(i,j) = y_i y_j x_i^T x_j\\
             &amp;\text{where} \quad A = y^T\\
             &amp;\text{note} \quad \max z \equiv \min -z
\end{aligned}
\]</span></p>
<p>And ipop is</p>
<p><span class="math display">\[
\begin{aligned}
\min_\alpha c &amp;\alpha + 0.5 x^T H x\\
             &amp;\text{s.t.} \quad b \le A \alpha \le b + r\\
             &amp;\text{s.t.} \quad l \le \alpha \le u\\
             &amp;\text{thus} \quad c=-1\\
             &amp;\text{thus} \quad u = \infty, l=0 \quad \text{but will set $u$ to a large number}\\
             &amp;\text{thus} \quad b=0, r=0 \quad \text{to remove this contraint}
\end{aligned}
\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">H &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="ot">NA</span>,n,n)
for (i in <span class="dv">1</span>:n){
  for (j in <span class="dv">1</span>:n){
    H[i,j] &lt;-<span class="st"> </span>y[i]*y[j]*<span class="kw">t</span>(X[i,])%*%X[j,]
  }
}

A &lt;-<span class="st"> </span><span class="kw">t</span>(y)
c &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rep</span>(-<span class="dv">1</span>,n))
l &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rep</span>(<span class="dv">0</span>,n))
b &lt;-<span class="st"> </span><span class="dv">0</span>
u &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rep</span>(<span class="fl">1e5</span>,n))
r &lt;-<span class="st"> </span><span class="dv">0</span>

alpha &lt;-<span class="st"> </span><span class="kw">primal</span>(<span class="kw">ipop</span>(c,H,A,b,l,u,r))

nonzero &lt;-<span class="st"> </span><span class="kw">which</span>(<span class="kw">abs</span>(alpha) &gt;<span class="st"> </span><span class="fl">1e-5</span>)
w &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="ot">NA</span>,<span class="dt">nrow=</span><span class="kw">length</span>(nonzero),<span class="dt">ncol=</span><span class="kw">ncol</span>(X))
for (i in <span class="kw">seq_along</span>(nonzero)){
  w[i,]  &lt;-<span class="st"> </span>alpha[nonzero[i]]*y[nonzero[i]]*X[nonzero[i],]
}
w &lt;-<span class="st"> </span><span class="kw">colSums</span>(w)

b0 &lt;-<span class="st"> </span>-(<span class="kw">max</span>(<span class="kw">sapply</span>(<span class="dv">1</span>:<span class="kw">sum</span>(y==-<span class="dv">1</span>), function(i) <span class="kw">matrix</span>(w,<span class="dt">ncol=</span><span class="dv">2</span>) %*%<span class="st"> </span>X[y==-<span class="dv">1</span>,][i,])) +<span class="st"> </span><span class="kw">min</span>(<span class="kw">sapply</span>(<span class="dv">1</span>:<span class="kw">sum</span>(y==<span class="dv">1</span>), function(i) <span class="kw">matrix</span>(w,<span class="dt">ncol=</span><span class="dv">2</span>) %*%<span class="st"> </span>X[y==<span class="dv">1</span>,][i,])))/<span class="dv">2</span>

slope &lt;-<span class="st"> </span>-w[<span class="dv">1</span>]/w[<span class="dv">2</span>]
intercept &lt;-<span class="st"> </span>-b0/w[<span class="dv">2</span>]

<span class="kw">plot</span>(X,<span class="dt">pch=</span><span class="dv">19</span>,<span class="dt">col=</span><span class="kw">ifelse</span>(<span class="dv">1</span>:n %in%<span class="st"> </span>nonzero,<span class="st">&quot;green&quot;</span>,<span class="st">&quot;black&quot;</span>)) <span class="co"># green ~ support vectors</span>
<span class="kw">abline</span>(intercept,slope,<span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</code></pre></div>
<p><img src="12_machinelearning_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sigma =<span class="st"> </span><span class="dv">1</span>
rbf &lt;-<span class="st"> </span><span class="kw">rbfdot</span>(<span class="dt">sigma =</span> sigma)
H_rbf &lt;-<span class="st"> </span><span class="kw">kernelMatrix</span>(rbf,X)</code></pre></div>
<div id="manual-rbf-kernal" class="section level3">
<h3><span class="header-section-number">13.3.1</span> Manual rbf kernal</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">XtX &lt;-<span class="st"> </span>X%*%<span class="kw">t</span>(X) <span class="co"># crossprod(t(X))</span>
XX &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">1</span>, n) %*%<span class="st"> </span><span class="kw">diag</span>(XtX)
D &lt;-<span class="st"> </span>XX -<span class="st"> </span><span class="dv">2</span> *<span class="st"> </span>XtX +<span class="st"> </span><span class="kw">t</span>(XX)
H &lt;-<span class="st"> </span><span class="kw">exp</span>(-D/(<span class="dv">2</span> *<span class="st"> </span>sigma))

alpha &lt;-<span class="st"> </span><span class="kw">primal</span>(<span class="kw">ipop</span>(c,H,A,b,l,u,r))

nonzero &lt;-<span class="st"> </span><span class="kw">which</span>(<span class="kw">abs</span>(alpha) &gt;<span class="st"> </span><span class="fl">1e-5</span>)
w &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="ot">NA</span>,<span class="dt">nrow=</span><span class="kw">length</span>(nonzero),<span class="dt">ncol=</span><span class="kw">ncol</span>(X))
for (i in <span class="kw">seq_along</span>(nonzero)){
  w[i,]  &lt;-<span class="st"> </span>alpha[nonzero[i]]*y[nonzero[i]]*X[nonzero[i],]
}
w &lt;-<span class="st"> </span><span class="kw">colSums</span>(w)

b0 &lt;-<span class="st"> </span>-(<span class="kw">max</span>(<span class="kw">sapply</span>(<span class="dv">1</span>:<span class="kw">sum</span>(y==-<span class="dv">1</span>), function(i) <span class="kw">matrix</span>(w,<span class="dt">ncol=</span><span class="dv">2</span>) %*%<span class="st"> </span>X[y==-<span class="dv">1</span>,][i,])) +<span class="st"> </span><span class="kw">min</span>(<span class="kw">sapply</span>(<span class="dv">1</span>:<span class="kw">sum</span>(y==<span class="dv">1</span>), function(i) <span class="kw">matrix</span>(w,<span class="dt">ncol=</span><span class="dv">2</span>) %*%<span class="st"> </span>X[y==<span class="dv">1</span>,][i,])))/<span class="dv">2</span>

slope &lt;-<span class="st"> </span>-w[<span class="dv">1</span>]/w[<span class="dv">2</span>]
intercept &lt;-<span class="st"> </span>-b0/w[<span class="dv">2</span>]

<span class="kw">plot</span>(X)
<span class="kw">abline</span>(intercept,slope,<span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</code></pre></div>
<p><img src="12_machinelearning_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
</div>
</div>
<div id="k-means" class="section level2">
<h2><span class="header-section-number">13.4</span> K-means</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(gganimate)

distance &lt;-<span class="st"> </span>function(x,c){
  d &lt;-<span class="st"> </span><span class="kw">apply</span>(c,<span class="dv">1</span>,function(y) <span class="kw">sqrt</span>((x[<span class="dv">1</span>]-y[<span class="dv">1</span>])^<span class="dv">2</span> +<span class="st"> </span>(x[<span class="dv">2</span>]-y[<span class="dv">2</span>])^<span class="dv">2</span>))
  w &lt;-<span class="st"> </span><span class="kw">which.min</span>(d)
  <span class="kw">return</span>(w)
}

<span class="kw">set.seed</span>(<span class="dv">123</span>)

x1 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>,<span class="dv">5</span>,<span class="dv">1</span>)
y1 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>,<span class="dv">0</span>,<span class="dv">2</span>)
x2 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>,<span class="dv">10</span>,<span class="dv">1</span>)
y2 &lt;-<span class="st"> </span><span class="dv">3</span> +<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>,<span class="dv">0</span>,<span class="dv">2</span>)
x3 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>,<span class="dv">0</span>,<span class="dv">1</span>)
y3 &lt;-<span class="st"> </span><span class="dv">8</span> +<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>,<span class="dv">0</span>,<span class="dv">2</span>)
x4 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>,<span class="dv">6</span>,<span class="dv">1</span>)
y4 &lt;-<span class="st"> </span><span class="dv">15</span> +<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>,<span class="dv">0</span>,<span class="dv">1</span>)
x5 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>,<span class="fl">5.5</span>,.<span class="dv">5</span>)
y5 &lt;-<span class="st"> </span><span class="dv">8</span> +<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>,<span class="dv">0</span>,<span class="dv">1</span>)

data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="st">&quot;x&quot;</span> =<span class="st"> </span><span class="kw">c</span>(x1,x2,x3,x4,x5), <span class="st">&quot;y&quot;</span> =<span class="st"> </span><span class="kw">c</span>(y1,y2,y3,y4,y5), <span class="st">&quot;class&quot;</span> =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">1</span>:<span class="dv">5</span>,<span class="dt">each=</span><span class="kw">length</span>(x1)))
c &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="kw">min</span>(data$x),<span class="kw">max</span>(data$x),<span class="kw">min</span>(data$x),<span class="kw">max</span>(data$x),<span class="kw">mean</span>(data$x),
              <span class="kw">min</span>(data$y),<span class="kw">max</span>(data$y),<span class="kw">max</span>(data$y),<span class="kw">min</span>(data$x),<span class="kw">mean</span>(data$y)),<span class="dt">ncol=</span><span class="dv">2</span>)
data.means &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="kw">cbind</span>(c,<span class="dv">0</span>))
<span class="kw">names</span>(data.means) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;x&quot;</span>,<span class="st">&quot;y&quot;</span>,<span class="st">&quot;class&quot;</span>)
<span class="kw">print</span>(true &lt;-<span class="st"> </span><span class="kw">ggplot</span>(data,<span class="kw">aes</span>(x,y,<span class="dt">colour=</span><span class="kw">factor</span>(class),<span class="dt">size=</span><span class="dv">2</span>)) +<span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">alpha=</span>.<span class="dv">7</span>) +<span class="st"> </span>
<span class="st">        </span><span class="kw">geom_point</span>(<span class="dt">data=</span>data.means,<span class="dt">colour=</span><span class="st">&quot;red&quot;</span>) +
<span class="st">        </span><span class="kw">geom_text</span>(<span class="dt">data=</span>data.means,<span class="dt">label=</span><span class="st">&quot;mean&quot;</span>,<span class="dt">vjust=</span><span class="dv">2</span>))
data$class &lt;-<span class="st"> </span><span class="dv">0</span>

c.old &lt;-<span class="st"> </span><span class="dv">0</span>

while (<span class="kw">abs</span>(<span class="kw">sum</span>(c-c.old)) !=<span class="st"> </span><span class="dv">0</span>){
  data$class &lt;-<span class="st"> </span><span class="kw">apply</span>(data[,<span class="dv">1</span>:<span class="dv">2</span>],<span class="dv">1</span>,function(x) <span class="kw">distance</span>(x,c))
  
  c.old &lt;-<span class="st"> </span>c
  c &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="kw">tapply</span>(data$x,data$class,mean),<span class="kw">tapply</span>(data$y,data$class,mean))
  
  data.means &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="kw">cbind</span>(c,<span class="dv">0</span>))
  <span class="kw">names</span>(data.means) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;x&quot;</span>,<span class="st">&quot;y&quot;</span>,<span class="st">&quot;class&quot;</span>)
}

group_means$iteration &lt;-<span class="st"> </span><span class="kw">as.integer</span>(group_means$iteration)
<span class="kw">ggplot</span>(<span class="dt">data=</span>group_means, <span class="kw">aes</span>(x,y)) +
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">color=</span><span class="st">&#39;black&#39;</span>,<span class="dt">alpha=</span>.<span class="dv">7</span>,<span class="dt">size=</span><span class="dv">8</span>) +
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data=</span>dat,<span class="kw">aes</span>(x,y,<span class="dt">color=</span><span class="kw">as.factor</span>(class)),<span class="dt">alpha=</span>.<span class="dv">3</span>,<span class="dt">size=</span><span class="dv">2</span>) +
<span class="st">  </span><span class="kw">scale_color_brewer</span>(<span class="dt">type=</span><span class="st">&#39;qual&#39;</span>,<span class="dt">palette=</span><span class="dv">2</span>) +
<span class="st">  </span><span class="kw">theme_bw</span>() +
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position=</span><span class="st">&#39;none&#39;</span>) +
<span class="st">  </span><span class="kw">transition_time</span>(iteration) +
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&#39;Iteration: {frame_time}&#39;</span>, <span class="dt">x =</span> <span class="st">&#39;&#39;</span>, <span class="dt">y =</span> <span class="st">&#39;&#39;</span>) +
<span class="st">  </span><span class="kw">ease_aes</span>(<span class="st">&#39;linear&#39;</span>)</code></pre></div>
<div class="figure">
<img src="figs/kmeans.gif" />

</div>
</div>
<div id="gaussian-mixtures" class="section level2">
<h2><span class="header-section-number">13.5</span> Gaussian Mixtures</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)

data &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rnorm</span>(<span class="dv">50</span>,<span class="dv">12</span>,<span class="dv">1</span>),<span class="kw">rnorm</span>(<span class="dv">50</span>,<span class="dv">4</span>,<span class="dv">1</span>))
ua &lt;-<span class="st"> </span>.<span class="dv">19</span>; sa &lt;-<span class="st"> </span>.<span class="dv">5</span>
ub &lt;-<span class="st"> </span>.<span class="dv">65</span>; sb &lt;-<span class="st"> </span>.<span class="dv">5</span>

for (i in <span class="dv">1</span>:<span class="dv">1000</span>){
  pda &lt;-<span class="st"> </span><span class="kw">exp</span>(-(data-ua)^<span class="dv">2</span>)
  pdb &lt;-<span class="st"> </span><span class="kw">exp</span>(-(data-ub)^<span class="dv">2</span>)
  
  pa &lt;-<span class="st"> </span>pda/(pda+pdb)
  pb &lt;-<span class="st"> </span>pdb/(pda+pdb)
  
  ua &lt;-<span class="st"> </span><span class="kw">sum</span>(pa*data)/<span class="kw">sum</span>(pa)
  sa &lt;-<span class="st"> </span><span class="kw">sum</span>(pa*(data-ua)^<span class="dv">2</span>)/<span class="kw">sum</span>(pa)
  
  ub &lt;-<span class="st"> </span><span class="kw">sum</span>(pb*data)/<span class="kw">sum</span>(pb)
  sb &lt;-<span class="st"> </span><span class="kw">sum</span>(pb*(data-ub)^<span class="dv">2</span>)/<span class="kw">sum</span>(pb)
  
  <span class="kw">cat</span>(ua,sa,<span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>,ub,sb,<span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">43</span>)

N &lt;-<span class="st"> </span><span class="dv">500</span>
p &lt;-<span class="st"> </span><span class="kw">rbinom</span>(<span class="dv">500</span>,<span class="dv">1</span>,.<span class="dv">3</span>)
y &lt;-<span class="st"> </span>(<span class="dv">1</span>-p)*<span class="kw">rnorm</span>(N,<span class="dv">4</span>,<span class="dv">1</span>) +<span class="st"> </span>p*<span class="kw">rnorm</span>(N,-<span class="dv">1</span>,<span class="dv">1</span>)

mu1 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">1</span>)
mu2 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">1</span>)
p &lt;-<span class="st"> </span>.<span class="dv">5</span>


for (t in <span class="dv">1</span>:<span class="dv">2500</span>){
 
  gamma1 &lt;-<span class="st"> </span><span class="kw">dnorm</span>(y,mu1,<span class="dv">1</span>)
  gamma2 &lt;-<span class="st"> </span><span class="kw">dnorm</span>(y,mu2,<span class="dv">1</span>)
  
  gamma &lt;-<span class="st"> </span>(p*gamma2)/((<span class="dv">1</span>-p)*gamma1 +<span class="st"> </span>p*gamma2)
  
  mu_hat1 &lt;-<span class="st"> </span><span class="kw">sum</span>((<span class="dv">1</span>-gamma)*y)/<span class="kw">sum</span>(<span class="dv">1</span>-gamma)
  mu_hat2 &lt;-<span class="st"> </span><span class="kw">sum</span>(gamma*y)/<span class="kw">sum</span>(gamma)
  
  mu1 &lt;-<span class="st"> </span>mu_hat1
  mu2 &lt;-<span class="st"> </span>mu_hat2
  
  p &lt;-<span class="st"> </span><span class="kw">sum</span>(gamma)/N
}

mu1</code></pre></div>
<pre><code>## [1] -1.109935</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mu2</code></pre></div>
<pre><code>## [1] 4.000447</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p</code></pre></div>
<pre><code>## [1] 0.6854409</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">iter &lt;-<span class="st"> </span><span class="dv">1000</span>
mu1_vector &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="dt">length=</span>iter)
mu2_vector &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="dt">length=</span>iter)
p_vector &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="dt">length=</span>iter)
for (t in <span class="dv">1</span>:iter){
  
  gamma1 &lt;-<span class="st"> </span><span class="kw">dnorm</span>(y,mu1,<span class="dv">1</span>)
  gamma2 &lt;-<span class="st"> </span><span class="kw">dnorm</span>(y,mu2,<span class="dv">1</span>)
  
  gamma &lt;-<span class="st"> </span>(p*gamma2)/((<span class="dv">1</span>-p)*gamma1 +<span class="st"> </span>p*gamma2)
  delta &lt;-<span class="st"> </span><span class="kw">rbinom</span>(N,<span class="dv">1</span>,gamma)
  
  mu_hat1 &lt;-<span class="st"> </span><span class="kw">sum</span>((<span class="dv">1</span>-delta)*y)/<span class="kw">sum</span>(<span class="dv">1</span>-delta)
  mu_hat2 &lt;-<span class="st"> </span><span class="kw">sum</span>(delta*y)/<span class="kw">sum</span>(delta)
  
  mu1 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">1</span>,mu_hat1,<span class="dv">1</span>)
  mu2 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">1</span>,mu_hat2,<span class="dv">1</span>)
  p &lt;-<span class="st"> </span><span class="kw">sum</span>(gamma)/N
  
  mu1_vector[t] &lt;-<span class="st"> </span>mu1
  mu2_vector[t] &lt;-<span class="st"> </span>mu2
  p_vector[t] &lt;-<span class="st"> </span>p
  
}

<span class="kw">qplot</span>(<span class="dv">1</span>:iter,mu1_vector,<span class="dt">geom=</span><span class="st">&#39;line&#39;</span>,<span class="dt">colour=</span><span class="dv">1</span>) +<span class="st"> </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dv">1</span>:iter,mu2_vector),<span class="dt">colour=</span><span class="dv">2</span>) +
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position=</span><span class="st">&#39;none&#39;</span>) +<span class="st"> </span><span class="kw">labs</span>(<span class="dt">title=</span><span class="st">&#39;mu&#39;</span>,<span class="dt">x=</span><span class="st">&#39;iteration&#39;</span>,<span class="dt">y=</span><span class="st">&#39;value&#39;</span>)</code></pre></div>
<p><img src="12_machinelearning_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qplot</span>(<span class="dv">1</span>:iter,p_vector,<span class="dt">geom=</span><span class="st">&#39;line&#39;</span>,<span class="dt">colour=</span><span class="dv">3</span>) +
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position=</span><span class="st">&#39;none&#39;</span>) +<span class="st"> </span><span class="kw">labs</span>(<span class="dt">title=</span><span class="st">&#39;p&#39;</span>,<span class="dt">x=</span><span class="st">&#39;iteration&#39;</span>,<span class="dt">y=</span><span class="st">&#39;value&#39;</span>)</code></pre></div>
<p><img src="12_machinelearning_files/figure-html/unnamed-chunk-13-2.png" width="672" /></p>
</div>
<div id="pca" class="section level2">
<h2><span class="header-section-number">13.6</span> PCA</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">4131</span>)

x &lt;-<span class="st"> </span><span class="dv">1</span>:<span class="dv">101</span>
y1 &lt;-<span class="st"> </span>x[<span class="dv">1</span>:<span class="dv">25</span>] +<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">25</span>,<span class="dv">0</span>,<span class="dv">20</span>)
y2 &lt;-<span class="st"> </span>x[<span class="dv">26</span>:<span class="dv">50</span>] +<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">25</span>,-<span class="dv">2</span>,<span class="dv">5</span>)
y3 &lt;-<span class="st"> </span>x[<span class="dv">51</span>:<span class="dv">75</span>] +<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">25</span>,<span class="dv">10</span>,<span class="dv">7</span>)
y4 &lt;-<span class="st"> </span>x[<span class="dv">76</span>:<span class="dv">101</span>] +<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">26</span>,<span class="dv">0</span>,<span class="dv">15</span>)
x &lt;-<span class="st"> </span><span class="kw">scale</span>(x)
y &lt;-<span class="st"> </span><span class="kw">scale</span>(<span class="kw">c</span>(y1,y2,y3,y4))
x &lt;-<span class="st"> </span><span class="kw">cbind</span>(x,y)
x &lt;-<span class="st"> </span>(x-<span class="kw">mean</span>(x))/<span class="kw">sd</span>(x)

df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="kw">cbind</span>(<span class="kw">data.frame</span>(x),<span class="kw">rep</span>(LETTERS[<span class="dv">1</span>:<span class="dv">4</span>],<span class="kw">c</span>(<span class="dv">25</span>,<span class="dv">25</span>,<span class="dv">25</span>,<span class="dv">26</span>))))
<span class="kw">names</span>(df) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&#39;x&#39;</span>,<span class="st">&#39;y&#39;</span>,<span class="st">&#39;group&#39;</span>)
<span class="kw">ggplot</span>(df,<span class="kw">aes</span>(<span class="dt">x=</span>x,<span class="dt">y=</span>y,<span class="dt">colour=</span>group)) +<span class="st"> </span><span class="kw">geom_point</span>()</code></pre></div>
<p><img src="12_machinelearning_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">evd &lt;-<span class="st"> </span><span class="kw">eigen</span>(<span class="kw">cov</span>(x))
pc1 &lt;-<span class="st"> </span>evd$vectors[,<span class="dv">1</span>]
pc2 &lt;-<span class="st"> </span>evd$vectors[,<span class="dv">2</span>]

proj1 &lt;-<span class="st"> </span>x %*%<span class="st"> </span>pc1
proj2 &lt;-<span class="st"> </span>x %*%<span class="st"> </span>pc2
vare &lt;-<span class="st"> </span><span class="kw">sum</span>(x[,<span class="dv">1</span>]*pc1[<span class="dv">1</span>])^<span class="dv">2</span> +<span class="st"> </span><span class="kw">sum</span>(x[,<span class="dv">2</span>]*pc1[<span class="dv">2</span>])^<span class="dv">2</span> 

df2 &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="kw">cbind</span>(proj1,<span class="dv">0</span>),df$group)
<span class="kw">names</span>(df2) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&#39;x&#39;</span>,<span class="st">&#39;y&#39;</span>,<span class="st">&#39;group&#39;</span>)
<span class="kw">ggplot</span>(df,<span class="kw">aes</span>(<span class="dt">x=</span>x,<span class="dt">y=</span>y,<span class="dt">colour=</span>group)) +<span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">alpha=</span>.<span class="dv">3</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data=</span>df2,<span class="dt">alpha=</span><span class="dv">1</span>)</code></pre></div>
<p><img src="12_machinelearning_files/figure-html/unnamed-chunk-14-2.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">4131</span>)
x1 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rnorm</span>(<span class="dv">100</span>,<span class="dv">68</span>,<span class="dv">5</span>),<span class="kw">rnorm</span>(<span class="dv">100</span>,<span class="dv">78</span>,<span class="dv">5</span>),<span class="kw">rnorm</span>(<span class="dv">100</span>,<span class="dv">63</span>,<span class="dv">4</span>))
x2 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rnorm</span>(<span class="dv">100</span>,<span class="dv">215</span>,<span class="dv">40</span>),<span class="kw">rnorm</span>(<span class="dv">100</span>,<span class="dv">200</span>,<span class="dv">20</span>),<span class="kw">rnorm</span>(<span class="dv">100</span>,<span class="dv">125</span>,<span class="dv">15</span>))
x3 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rnorm</span>(<span class="dv">100</span>,<span class="dv">280</span>,<span class="dv">50</span>),<span class="kw">rnorm</span>(<span class="dv">100</span>,<span class="dv">180</span>,<span class="dv">15</span>),<span class="kw">rnorm</span>(<span class="dv">100</span>,<span class="dv">95</span>,<span class="dv">15</span>))

x1 &lt;-<span class="st"> </span><span class="kw">scale</span>(x1)
x2 &lt;-<span class="st"> </span><span class="kw">scale</span>(x2)
x3 &lt;-<span class="st"> </span><span class="kw">scale</span>(x3)

x &lt;-<span class="st"> </span><span class="kw">cbind</span>(x1,x2,x3)

df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="kw">cbind</span>(<span class="kw">data.frame</span>(x),<span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;Compact Guys&quot;</span>,<span class="st">&quot;Lanky Guys&quot;</span>,<span class="st">&quot;Women&quot;</span>),<span class="dt">each=</span><span class="dv">100</span>)))
<span class="kw">names</span>(df) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&#39;x1&#39;</span>,<span class="st">&#39;x2&#39;</span>,<span class="st">&#39;x3&#39;</span>,<span class="st">&#39;group&#39;</span>)

evd &lt;-<span class="st"> </span><span class="kw">eigen</span>(<span class="kw">cov</span>(x))
pc1 &lt;-<span class="st"> </span>evd$vectors[,<span class="dv">1</span>]
pc2 &lt;-<span class="st"> </span>evd$vectors[,<span class="dv">2</span>]
pc3 &lt;-<span class="st"> </span>evd$vectors[,<span class="dv">3</span>]

proj1 &lt;-<span class="st"> </span>x %*%<span class="st"> </span>pc1
proj2 &lt;-<span class="st"> </span>x %*%<span class="st"> </span>pc2
proj3 &lt;-<span class="st"> </span>x %*%<span class="st"> </span>pc3
vare &lt;-<span class="st"> </span><span class="kw">sum</span>(x[,<span class="dv">1</span>]*pc1[<span class="dv">1</span>])^<span class="dv">2</span> +<span class="st"> </span><span class="kw">sum</span>(x[,<span class="dv">2</span>]*pc1[<span class="dv">2</span>])^<span class="dv">2</span> +<span class="st"> </span><span class="kw">sum</span>(x[,<span class="dv">3</span>]*pc1[<span class="dv">3</span>])^<span class="dv">2</span> 

df2 &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="kw">cbind</span>(proj1,proj2),df$group)
<span class="kw">names</span>(df2) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&#39;x&#39;</span>,<span class="st">&#39;y&#39;</span>,<span class="st">&#39;group&#39;</span>)
<span class="kw">ggplot</span>(df2,<span class="kw">aes</span>(<span class="dt">x=</span>x,<span class="dt">y=</span>y,<span class="dt">colour=</span>group)) +<span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">alpha=</span><span class="dv">1</span>)</code></pre></div>
<p><img src="12_machinelearning_files/figure-html/unnamed-chunk-14-3.png" width="672" /></p>
</div>
<div id="viterbi-algorithm" class="section level2">
<h2><span class="header-section-number">13.7</span> Viterbi Algorithm</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">init &lt;-<span class="st"> </span><span class="kw">log</span>(<span class="kw">c</span>(.<span class="dv">5</span>,.<span class="dv">5</span>),<span class="dv">2</span>)
trans1 &lt;-<span class="st"> </span><span class="kw">log</span>(<span class="kw">c</span>(.<span class="dv">5</span>,.<span class="dv">5</span>),<span class="dv">2</span>)
trans2 &lt;-<span class="st"> </span><span class="kw">log</span>(<span class="kw">c</span>(.<span class="dv">4</span>,.<span class="dv">6</span>),<span class="dv">2</span>)
vis1 &lt;-<span class="st"> </span><span class="kw">log</span>(<span class="kw">c</span>(.<span class="dv">2</span>,.<span class="dv">3</span>,.<span class="dv">3</span>,.<span class="dv">2</span>),<span class="dv">2</span>)
vis2 &lt;-<span class="st"> </span><span class="kw">log</span>(<span class="kw">c</span>(.<span class="dv">3</span>,.<span class="dv">2</span>,.<span class="dv">2</span>,.<span class="dv">3</span>),<span class="dv">2</span>)

seq &lt;-<span class="st"> &quot;GGCACTGAA&quot;</span>
dic &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;A&quot;</span>,<span class="st">&quot;C&quot;</span>,<span class="st">&quot;G&quot;</span>,<span class="st">&quot;T&quot;</span>)

viterbi &lt;-<span class="st"> </span>function(seq){
  if (<span class="kw">nchar</span>(seq) ==<span class="st"> </span><span class="dv">1</span>){
    
    nt &lt;-<span class="st"> </span><span class="kw">which</span>(dic ==<span class="st"> </span>seq)
    <span class="kw">print</span>(comp &lt;-<span class="st"> </span><span class="kw">c</span>(init[<span class="dv">1</span>] +<span class="st"> </span>vis1[nt], init[<span class="dv">2</span>] +<span class="st"> </span>vis2[nt]))
    <span class="kw">return</span>(<span class="kw">c</span>(comp))
    
  }else{
    
    nt &lt;-<span class="st"> </span><span class="kw">which</span>(dic ==<span class="st"> </span><span class="kw">substr</span>(seq,<span class="kw">nchar</span>(seq),<span class="kw">nchar</span>(seq)))
    past &lt;-<span class="st"> </span><span class="kw">viterbi</span>(<span class="kw">substr</span>(seq,<span class="dv">1</span>,<span class="kw">nchar</span>(seq)-<span class="dv">1</span>))
    if (past[<span class="dv">1</span>] &gt;<span class="st"> </span>past[<span class="dv">2</span>]) ans &lt;-<span class="st"> </span><span class="dv">1</span> else ans &lt;-<span class="st"> </span><span class="dv">2</span>
    <span class="kw">print</span>(ans)
    <span class="kw">print</span>(
      choice &lt;-<span class="st"> </span><span class="kw">c</span>(
        vis1[nt] +<span class="st"> </span><span class="kw">max</span>(past[<span class="dv">1</span>] +<span class="st"> </span>trans1[<span class="dv">1</span>], past[<span class="dv">2</span>] +<span class="st"> </span>trans2[<span class="dv">1</span>]),
        vis2[nt] +<span class="st"> </span><span class="kw">max</span>(past[<span class="dv">1</span>] +<span class="st"> </span>trans1[<span class="dv">2</span>], past[<span class="dv">2</span>] +<span class="st"> </span>trans2[<span class="dv">2</span>])
      )
    )
  }
}

init &lt;-<span class="st"> </span><span class="kw">c</span>(.<span class="dv">5</span>,.<span class="dv">5</span>)
trans1 &lt;-<span class="st"> </span><span class="kw">c</span>(.<span class="dv">5</span>,.<span class="dv">5</span>)
trans2 &lt;-<span class="st"> </span><span class="kw">c</span>(.<span class="dv">4</span>,.<span class="dv">6</span>)
vis1 &lt;-<span class="st"> </span><span class="kw">c</span>(.<span class="dv">2</span>,.<span class="dv">3</span>,.<span class="dv">3</span>,.<span class="dv">2</span>)
vis2 &lt;-<span class="st"> </span><span class="kw">c</span>(.<span class="dv">3</span>,.<span class="dv">2</span>,.<span class="dv">2</span>,.<span class="dv">3</span>)

path &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">3</span>,<span class="dv">2</span>,<span class="dv">1</span>)

latent1 &lt;-<span class="st"> </span><span class="dv">0</span>
latent2 &lt;-<span class="st"> </span><span class="dv">0</span>

prev1 &lt;-<span class="st"> </span>init[<span class="dv">1</span>]*vis1[path[<span class="dv">1</span>]]
prev2 &lt;-<span class="st"> </span>init[<span class="dv">2</span>]*vis2[path[<span class="dv">1</span>]]
for (i in <span class="dv">2</span>:<span class="kw">length</span>(path)){

  prevtemp1 &lt;-<span class="st"> </span>prev1*trans1[<span class="dv">1</span>]*vis1[path[i]] +<span class="st"> </span>prev2*trans2[<span class="dv">1</span>]*vis1[path[i]]
  prevtemp2 &lt;-<span class="st"> </span>prev2*trans2[<span class="dv">2</span>]*vis2[path[i]] +<span class="st"> </span>prev1*trans1[<span class="dv">2</span>]*vis2[path[i]]
  
  prev1 &lt;-<span class="st"> </span>prevtemp1
  prev2 &lt;-<span class="st"> </span>prevtemp2
}
<span class="kw">print</span>(prev1 +<span class="st"> </span>prev2)</code></pre></div>
<pre><code>## [1] 0.00384315</code></pre>
</div>
<div id="gradient-descent" class="section level2">
<h2><span class="header-section-number">13.8</span> Gradient Descent</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">12345</span>) 

x &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">0</span>, <span class="dt">to =</span> <span class="dv">2</span>, <span class="dt">by =</span> <span class="fl">0.1</span>), <span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>)
y &lt;-<span class="st"> </span><span class="dv">2</span> *<span class="st"> </span>x +<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">50</span>)
x &lt;-<span class="st"> </span>x -<span class="st"> </span><span class="kw">mean</span>(x)
y &lt;-<span class="st"> </span>y -<span class="st"> </span><span class="kw">mean</span>(y)

X &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="dv">1</span>,x)
y &lt;-<span class="st"> </span><span class="kw">as.vector</span>(y)

iter &lt;-<span class="st"> </span><span class="dv">5000</span>
a &lt;-<span class="st"> </span><span class="fl">0.01</span>
b &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>,<span class="kw">ncol</span>(X)) <span class="co"># b0</span>

loss &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>,<span class="dt">nrow=</span>iter,<span class="dt">ncol=</span><span class="dv">1</span>)
B &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>,<span class="dt">nrow=</span>iter,<span class="dt">ncol=</span><span class="dv">1</span>)
for (i in <span class="dv">1</span>:iter){
  fb &lt;-<span class="st"> </span>(<span class="dv">1</span>/<span class="dv">2</span>) *<span class="st"> </span><span class="kw">norm</span>(y -<span class="st"> </span>X %*%<span class="st"> </span>b,<span class="st">&quot;F&quot;</span>)
  loss[i,] &lt;-<span class="st"> </span>fb
  grad.fb &lt;-<span class="st"> </span>-(<span class="kw">t</span>(X) %*%<span class="st"> </span>(y -<span class="st"> </span>X %*%<span class="st"> </span>b)) <span class="co"># flip sign to DESCEND</span>
  b &lt;-<span class="st"> </span>b -<span class="st"> </span>a*grad.fb
  B[i] &lt;-<span class="st"> </span>b[<span class="dv">2</span>,]
}

out &lt;-<span class="st"> </span><span class="kw">pretty</span>(<span class="kw">c</span>(<span class="kw">min</span>(x)-<span class="dv">2</span>,<span class="kw">max</span>(x)+<span class="dv">6</span>),<span class="dv">10000</span>)
out2 &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="dv">1</span>:<span class="kw">length</span>(out), function(x) (<span class="dv">1</span>/<span class="dv">2</span>) *<span class="st"> </span><span class="kw">norm</span>(y -<span class="st"> </span>X %*%<span class="st"> </span><span class="kw">rbind</span>(<span class="dv">0</span>,out)[,x],<span class="st">&quot;F&quot;</span>))

<span class="kw">ggplot</span>(<span class="kw">tibble</span>(<span class="dt">b=</span>B,<span class="dt">loss=</span>loss,<span class="dt">iteration=</span><span class="dv">1</span>:<span class="kw">length</span>(b)) %&gt;%<span class="st"> </span><span class="kw">filter</span>(iteration &lt;<span class="st"> </span><span class="dv">50</span>),<span class="kw">aes</span>(b,loss)) +<span class="st"> </span>
<span class="kw">ggplot</span>(<span class="kw">tibble</span>(<span class="dt">b=</span>B,<span class="dt">loss=</span>loss,<span class="dt">iteration=</span><span class="dv">1</span>:<span class="kw">length</span>(b)) %&gt;%<span class="st"> </span><span class="kw">filter</span>(iteration &lt;<span class="st"> </span><span class="dv">50</span>),<span class="kw">aes</span>(b,loss)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">data=</span><span class="kw">tibble</span>(<span class="dt">x=</span>out,<span class="dt">y=</span>out2),<span class="kw">aes</span>(x,y),<span class="dt">alpha=</span>.<span class="dv">3</span>,<span class="dt">size=</span><span class="dv">2</span>) +
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">color=</span><span class="st">&#39;red&#39;</span>,<span class="dt">alpha=</span><span class="dv">1</span>,<span class="dt">size=</span><span class="fl">1.2</span>) +
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">color=</span><span class="st">&#39;red&#39;</span>,<span class="dt">alpha=</span>.<span class="dv">8</span>,<span class="dt">size=</span>.<span class="dv">5</span>) +
<span class="st">  </span><span class="kw">transition_reveal</span>(iteration,<span class="dt">range=</span><span class="kw">c</span>(1L,25L)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">ease_aes</span>(<span class="st">&#39;quadratic-out&#39;</span>) +
<span class="st">  </span><span class="kw">theme_bw</span>() +
<span class="st">  </span><span class="kw">xlim</span>(<span class="dv">0</span>,<span class="fl">3.75</span>) +<span class="st"> </span><span class="kw">ylim</span>(<span class="dv">2</span>,<span class="dv">6</span>) +<span class="st"> </span><span class="kw">theme</span>(<span class="dt">aspect.ratio=</span>.<span class="dv">5</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&#39;&#39;</span>, <span class="dt">x =</span> <span class="st">&#39;&#39;</span>, <span class="dt">y =</span> <span class="st">&#39;Loss&#39;</span>)</code></pre></div>
<div class="figure">
<img src="figs/graddesc.gif" />

</div>
<div id="linear-regression" class="section level3">
<h3><span class="header-section-number">13.8.1</span> Linear Regression</h3>
<div id="sgd" class="section level4">
<h4><span class="header-section-number">13.8.1.1</span> SGD</h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">N &lt;-<span class="st"> </span><span class="dv">50</span>
X &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="dv">1</span>,<span class="kw">runif</span>(N,-<span class="dv">1</span>,<span class="dv">1</span>),<span class="kw">runif</span>(N,-<span class="dv">1</span>,<span class="dv">1</span>))
k &lt;-<span class="st"> </span><span class="kw">ncol</span>(X)
theta &lt;-<span class="st"> </span><span class="kw">rnorm</span>(k)
y &lt;-<span class="st"> </span>X %*%<span class="st"> </span>theta +<span class="st"> </span><span class="kw">rnorm</span>(N)

th &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rep</span>(<span class="dv">0</span>,k),<span class="dt">nrow=</span>k)
eta &lt;-<span class="st"> </span><span class="fl">0.01</span>
for (i in <span class="dv">1</span>:<span class="dv">10000</span>){
  grad &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rep</span>(<span class="dv">0</span>,k),<span class="dt">nrow=</span>k)
  for (j in <span class="dv">1</span>:N){
    grad &lt;-<span class="st"> </span>grad -<span class="st"> </span>X[j,] %*%<span class="st"> </span>(y[j]-X[j,]%*%th)
  }
  th &lt;-<span class="st"> </span>th -<span class="st"> </span>eta*grad
}

<span class="kw">t</span>(th)</code></pre></div>
<pre><code>##            [,1]      [,2]      [,3]
## [1,] 0.07688319 -1.346672 0.9435691</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coef</span>(<span class="kw">lm</span>(y ~<span class="st"> </span>X[,-<span class="dv">1</span>]))</code></pre></div>
<pre><code>## (Intercept)    X[, -1]1    X[, -1]2 
##  0.07688319 -1.34667198  0.94356907</code></pre>
</div>
<div id="vectorized" class="section level4">
<h4><span class="header-section-number">13.8.1.2</span> Vectorized</h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">th &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rep</span>(<span class="dv">0</span>,k),<span class="dt">nrow=</span>k)
eta &lt;-<span class="st"> </span><span class="fl">0.01</span>
for (i in <span class="dv">1</span>:<span class="dv">10000</span>){
  grad &lt;-<span class="st"> </span><span class="kw">t</span>(X) %*%<span class="st"> </span>(X %*%<span class="st"> </span>th -<span class="st"> </span>y)
  th &lt;-<span class="st"> </span>th -<span class="st"> </span>eta*grad
}

<span class="kw">t</span>(th)</code></pre></div>
<pre><code>##            [,1]      [,2]      [,3]
## [1,] 0.07688319 -1.346672 0.9435691</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coef</span>(<span class="kw">lm</span>(y ~<span class="st"> </span>X[,-<span class="dv">1</span>]))</code></pre></div>
<pre><code>## (Intercept)    X[, -1]1    X[, -1]2 
##  0.07688319 -1.34667198  0.94356907</code></pre>
</div>
</div>
<div id="logistic-regression" class="section level3">
<h3><span class="header-section-number">13.8.2</span> Logistic Regression</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">invlogit &lt;-<span class="st"> </span>function(x) <span class="dv">1</span>/(<span class="dv">1</span>+<span class="kw">exp</span>(-x))

N &lt;-<span class="st"> </span><span class="dv">500</span>
X &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="dv">1</span>,<span class="kw">runif</span>(N,-<span class="dv">1</span>,<span class="dv">1</span>))
k &lt;-<span class="st"> </span><span class="kw">ncol</span>(X)
theta &lt;-<span class="st"> </span><span class="kw">rnorm</span>(k)
y &lt;-<span class="st"> </span><span class="kw">rbinom</span>(N,<span class="dv">1</span>,<span class="kw">invlogit</span>(X %*%<span class="st"> </span>theta))


N &lt;-<span class="st"> </span><span class="dv">500</span>
X &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="kw">runif</span>(N,-<span class="dv">1</span>,<span class="dv">1</span>),<span class="kw">runif</span>(N,-<span class="dv">1</span>,<span class="dv">1</span>))
theta &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">1.5</span>,-<span class="dv">3</span>)
y &lt;-<span class="st"> </span><span class="dv">1</span>+<span class="kw">ifelse</span>(X %*%<span class="st"> </span>theta +<span class="st"> </span><span class="kw">rnorm</span>(N) &lt;<span class="st"> </span><span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>)</code></pre></div>
<div id="sgd-1" class="section level4">
<h4><span class="header-section-number">13.8.2.1</span> SGD</h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">th &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rep</span>(<span class="dv">0</span>,k),<span class="dt">nrow=</span>k)
eta &lt;-<span class="st"> </span><span class="fl">0.25</span>
for (i in <span class="dv">1</span>:<span class="dv">5000</span>){
  g &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rep</span>(<span class="dv">0</span>,k),<span class="dt">nrow=</span>k)
  for (j in <span class="dv">1</span>:N){
    g &lt;-<span class="st"> </span>g -<span class="st"> </span>X[j,] %*%<span class="st"> </span>(y[j]-<span class="kw">invlogit</span>(X[j,]%*%th))
  }
  th &lt;-<span class="st"> </span>th -<span class="st"> </span>eta*g
}
scores &lt;-<span class="st"> </span>X %*%<span class="st"> </span>th
pred &lt;-<span class="st"> </span><span class="kw">ifelse</span>(scores&gt;<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>)

<span class="kw">plot</span>(X,<span class="dt">col=</span>y<span class="dv">+1</span>,<span class="dt">pch=</span><span class="dv">19</span>)</code></pre></div>
<p><img src="12_machinelearning_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(X,<span class="dt">col=</span>pred<span class="dv">+1</span>,<span class="dt">pch=</span><span class="dv">19</span>)</code></pre></div>
<p><img src="12_machinelearning_files/figure-html/unnamed-chunk-20-2.png" width="672" /></p>
</div>
<div id="vectorized-1" class="section level4">
<h4><span class="header-section-number">13.8.2.2</span> Vectorized</h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">th &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rep</span>(<span class="dv">0</span>,k),<span class="dt">nrow=</span>k)
eta &lt;-<span class="st"> </span>.<span class="dv">01</span>
for (i in <span class="dv">1</span>:<span class="dv">10000</span>){
  g &lt;-<span class="st"> </span><span class="kw">t</span>(X) %*%<span class="st"> </span>(<span class="kw">invlogit</span>(X %*%<span class="st"> </span>th)-y)
  th &lt;-<span class="st"> </span>th -<span class="st"> </span>eta*g
}
scores &lt;-<span class="st"> </span>X %*%<span class="st"> </span>th
pred &lt;-<span class="st"> </span><span class="kw">ifelse</span>(scores&gt;<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>)

<span class="kw">plot</span>(X,<span class="dt">col=</span>y<span class="dv">+1</span>,<span class="dt">pch=</span><span class="dv">19</span>)</code></pre></div>
<p><img src="12_machinelearning_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(X,<span class="dt">col=</span>pred<span class="dv">+1</span>,<span class="dt">pch=</span><span class="dv">19</span>)</code></pre></div>
<p><img src="12_machinelearning_files/figure-html/unnamed-chunk-21-2.png" width="672" /></p>
</div>
<div id="newtons" class="section level4">
<h4><span class="header-section-number">13.8.2.3</span> Newtons</h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">th &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rep</span>(<span class="dv">0</span>,k),<span class="dt">nrow=</span>k)
eta &lt;-<span class="st"> </span><span class="dv">1</span>
for (i in <span class="dv">1</span>:<span class="dv">5000</span>){
  p &lt;-<span class="st"> </span><span class="kw">invlogit</span>(X %*%<span class="st"> </span>th)
  S &lt;-<span class="st"> </span><span class="kw">diag</span>(<span class="kw">c</span>(p *<span class="st"> </span>(<span class="dv">1</span>-p)),N,N)
  H &lt;-<span class="st"> </span><span class="kw">t</span>(X) %*%<span class="st"> </span>S %*%<span class="st"> </span>X
  g &lt;-<span class="st"> </span><span class="kw">t</span>(X) %*%<span class="st"> </span>(p-y)
  th &lt;-<span class="st"> </span>th -<span class="st"> </span>eta *<span class="st"> </span><span class="kw">solve</span>(H) %*%<span class="st"> </span>g
}
scores &lt;-<span class="st"> </span>X %*%<span class="st"> </span>th
pred &lt;-<span class="st"> </span><span class="kw">ifelse</span>(scores&gt;<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>)

<span class="kw">plot</span>(X,<span class="dt">col=</span>y<span class="dv">+1</span>,<span class="dt">pch=</span><span class="dv">19</span>)</code></pre></div>
<p><img src="12_machinelearning_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(X,<span class="dt">col=</span>pred<span class="dv">+1</span>,<span class="dt">pch=</span><span class="dv">19</span>)</code></pre></div>
<p><img src="12_machinelearning_files/figure-html/unnamed-chunk-22-2.png" width="672" /></p>
</div>
</div>
<div id="softmax-regression" class="section level3">
<h3><span class="header-section-number">13.8.3</span> Softmax regression</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">N &lt;-<span class="st"> </span><span class="dv">1000</span>
X &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="dv">1</span>,<span class="kw">runif</span>(N,<span class="dv">0</span>,<span class="dv">100</span>),<span class="kw">runif</span>(N,<span class="dv">0</span>,<span class="dv">100</span>))
theta &lt;-<span class="st"> </span><span class="kw">rbind</span>(<span class="kw">c</span>(<span class="dv">100</span>,-<span class="dv">1</span>,-<span class="dv">1</span>),<span class="kw">c</span>(<span class="dv">100</span>,<span class="dv">0</span>,-<span class="dv">2</span>))
y &lt;-<span class="st"> </span><span class="dv">1</span> +<span class="st"> </span><span class="kw">ifelse</span>(X %*%<span class="st"> </span>theta[<span class="dv">1</span>,] +<span class="st"> </span><span class="kw">rnorm</span>(N,<span class="dv">0</span>,<span class="dv">10</span>) &lt;<span class="st"> </span><span class="dv">0</span>, <span class="dv">0</span>,
              <span class="kw">ifelse</span>(X %*%<span class="st"> </span>theta[<span class="dv">2</span>,] +<span class="st"> </span><span class="kw">rnorm</span>(N,<span class="dv">0</span>,<span class="dv">10</span>) &lt;<span class="st"> </span><span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>))
X[,-<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">scale</span>(X[,-<span class="dv">1</span>])
K &lt;-<span class="st"> </span><span class="kw">ncol</span>(X)
J &lt;-<span class="st"> </span><span class="kw">length</span>(<span class="kw">unique</span>(y))</code></pre></div>
<div id="sgd-2" class="section level4">
<h4><span class="header-section-number">13.8.3.1</span> SGD</h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">th &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rep</span>(<span class="dv">0</span>,K*J),<span class="dt">nrow=</span>K,<span class="dt">ncol=</span>J)
g &lt;-<span class="st"> </span>th
eta &lt;-<span class="st"> </span>.<span class="dv">5</span>
for (i in <span class="dv">1</span>:<span class="dv">5000</span>){
  a &lt;-<span class="st"> </span><span class="kw">exp</span>(X %*%<span class="st"> </span>th) <span class="co"># exp(thetak&#39; * xi)</span>
  a_sum &lt;-<span class="st"> </span><span class="kw">rowSums</span>(a) <span class="co"># SUMexp(thetaj&#39; * xi)</span>
  p &lt;-<span class="st"> </span><span class="kw">t</span>(<span class="kw">sapply</span>(<span class="dv">1</span>:N,function(n) a[n,]/a_sum[n])) <span class="co"># P(yi=k|xi,theta) = exp(thetak&#39; * xi)/SUMexp(thetaj&#39; * xi)</span>
  
  <span class="co"># -SUM[xi * (1{yi=k} - P(yi=k|xi;theta))] = SUM[xi * (P(yi=k|xi;theta)) - 1{yi=k}]</span>
  <span class="co"># therefore P(yi=k|xi;theta)) - 1{yi=k} is simply p-1 for all p where yi=k</span>
  
  for (n in <span class="dv">1</span>:N){
    p[n,y[n]] &lt;-<span class="st"> </span>p[n,y[n]] -<span class="st"> </span><span class="dv">1</span> <span class="co"># P(yi=k|xi;theta)) - 1{yi=k}</span>
  }
  p &lt;-<span class="st"> </span>p/N <span class="co"># this is not necessary but adjusts the size of the estimates to avoid very large values</span>
  g &lt;-<span class="st"> </span><span class="kw">t</span>(X) %*%<span class="st"> </span>p <span class="co"># SUM[xi * (P(yi=k|xi;theta)) - 1{yi=k}]</span>
  
  th &lt;-<span class="st"> </span>th -<span class="st"> </span>eta*g
}

scores &lt;-<span class="st"> </span>X %*%<span class="st"> </span>th 
pred &lt;-<span class="st"> </span><span class="kw">apply</span>(scores,<span class="dv">1</span>,which.max)

<span class="kw">plot</span>(X[,-<span class="dv">1</span>],<span class="dt">col=</span>y,<span class="dt">pch=</span><span class="dv">19</span>)</code></pre></div>
<p><img src="12_machinelearning_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(X[,-<span class="dv">1</span>],<span class="dt">col=</span>pred,<span class="dt">pch=</span><span class="dv">19</span>)</code></pre></div>
<p><img src="12_machinelearning_files/figure-html/unnamed-chunk-24-2.png" width="672" /></p>
</div>
<div id="sgd-with-bias-term" class="section level4">
<h4><span class="header-section-number">13.8.3.2</span> SGD with bias term</h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">N &lt;-<span class="st"> </span><span class="dv">100</span>
D &lt;-<span class="st"> </span><span class="dv">2</span>
K &lt;-<span class="st"> </span><span class="dv">3</span>
X &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>,N*K,D)
y &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>,N*K)
ind1 &lt;-<span class="st"> </span><span class="dv">0</span>
ind2 &lt;-<span class="st"> </span><span class="dv">0</span>
for (k in <span class="dv">1</span>:K){
  r &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dt">length=</span>N)
  t &lt;-<span class="st"> </span><span class="kw">seq</span>((k<span class="dv">-1</span>)*<span class="dv">4</span>,(k)*<span class="dv">4</span>,<span class="dt">length=</span>N) +<span class="st"> </span><span class="kw">rnorm</span>(N)*<span class="fl">0.2</span>
  X[(<span class="dv">1</span>+ind1):(N+ind2),] &lt;-<span class="st"> </span><span class="kw">cbind</span>(r*<span class="kw">sin</span>(t), r*<span class="kw">cos</span>(t))
  y[(<span class="dv">1</span>+ind1):(N+ind2)] &lt;-<span class="st"> </span>k
  ind1 &lt;-<span class="st"> </span>ind1 +<span class="st"> </span>N
  ind2 &lt;-<span class="st"> </span>ind2 +<span class="st"> </span>N
}

W &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="fl">0.01</span>*<span class="kw">rnorm</span>(D*K),D,K)
b &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>,<span class="dv">1</span>,K)
step &lt;-<span class="st"> </span><span class="dv">1</span>
reg &lt;-<span class="st"> </span><span class="fl">1e-3</span>

for (i in <span class="dv">1</span>:<span class="dv">5000</span>){
  a &lt;-<span class="st"> </span><span class="kw">exp</span>(X %*%<span class="st"> </span>W +<span class="st"> </span><span class="kw">rep</span>(b,N*K))
  a_sum &lt;-<span class="st"> </span><span class="kw">rowSums</span>(a)
  p &lt;-<span class="st"> </span><span class="kw">t</span>(<span class="kw">sapply</span>(<span class="dv">1</span>:(N*K),function(n) a[n,]/a_sum[n]))
  
  for (n in <span class="dv">1</span>:(N*K)){
    p[n,y[n]] &lt;-<span class="st"> </span>p[n,y[n]] -<span class="st"> </span><span class="dv">1</span>
  }
  p &lt;-<span class="st"> </span>p/(N*K)
  
  gW &lt;-<span class="st"> </span><span class="kw">t</span>(X) %*%<span class="st"> </span>p
  gb &lt;-<span class="st"> </span><span class="kw">colSums</span>(p)
  
  gW &lt;-<span class="st"> </span>gW +<span class="st"> </span>reg*W
  W &lt;-<span class="st"> </span>W +<span class="st"> </span>-step*gW
  b &lt;-<span class="st"> </span>b +<span class="st"> </span>-step*gb
}

scores &lt;-<span class="st"> </span>X %*%<span class="st"> </span>W +<span class="st"> </span><span class="kw">rep</span>(b,N*K)
pred &lt;-<span class="st"> </span><span class="kw">apply</span>(scores,<span class="dv">1</span>,which.max)

<span class="kw">plot</span>(X,<span class="dt">col=</span>y,<span class="dt">pch=</span><span class="dv">19</span>)</code></pre></div>
<p><img src="12_machinelearning_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(X,<span class="dt">col=</span>pred,<span class="dt">pch=</span><span class="dv">19</span>)</code></pre></div>
<p><img src="12_machinelearning_files/figure-html/unnamed-chunk-25-2.png" width="672" /></p>
</div>
</div>
</div>
<div id="nonparametric-bayesian-processes" class="section level2">
<h2><span class="header-section-number">13.9</span> Nonparametric Bayesian Processes</h2>
<div id="chinese-restaurant" class="section level3">
<h3><span class="header-section-number">13.9.1</span> Chinese Restaurant</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">chinese_restaurant &lt;-<span class="st"> </span>function(N, alpha){
  tables &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="dt">length=</span>N)
  tables[<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="dv">1</span>
  open &lt;-<span class="st"> </span><span class="dv">2</span>
  for (i in <span class="dv">2</span>:N){
    choice &lt;-<span class="st"> </span><span class="kw">rbinom</span>(<span class="dv">1</span>,<span class="dv">1</span>,alpha/(i+alpha))
    if (choice ==<span class="st"> </span><span class="dv">1</span>){
      tables[open] &lt;-<span class="st"> </span>tables[open] +<span class="st"> </span><span class="dv">1</span>
      open &lt;-<span class="st"> </span>open +<span class="st"> </span><span class="dv">1</span>
    }else{
      occupied &lt;-<span class="st"> </span><span class="kw">which</span>(tables !=<span class="st"> </span><span class="dv">0</span>)
      prob &lt;-<span class="st"> </span>tables[occupied]/(i+alpha)
      seat &lt;-<span class="st"> </span><span class="kw">sample</span>(occupied,<span class="dv">1</span>,<span class="ot">FALSE</span>,prob)
      tables[seat] &lt;-<span class="st"> </span>tables[seat] +<span class="st"> </span><span class="dv">1</span>
    }
  }
  <span class="kw">return</span>(tables)
}

<span class="kw">chinese_restaurant</span>(<span class="dv">30</span>,<span class="dv">10</span>)</code></pre></div>
<pre><code>##  [1] 8 3 3 2 1 2 1 4 1 1 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</code></pre>
</div>
<div id="polyas-urn" class="section level3">
<h3><span class="header-section-number">13.9.2</span> Polyas Urn</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">polyas_urn &lt;-<span class="st"> </span>function(N,alpha){
  balls &lt;-<span class="st"> </span><span class="ot">NULL</span>
  for (i in <span class="dv">1</span>:N){
    choice &lt;-<span class="st"> </span><span class="kw">rbinom</span>(<span class="dv">1</span>,<span class="dv">1</span>,alpha/(<span class="kw">length</span>(balls)+alpha))
    if (choice ==<span class="st"> </span><span class="dv">1</span>){
      ball &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">1</span>)
      balls &lt;-<span class="st"> </span><span class="kw">c</span>(balls,ball)
    }else{
      ball &lt;-<span class="st"> </span>balls[<span class="kw">sample</span>(<span class="dv">1</span>:<span class="kw">length</span>(balls),<span class="dv">1</span>)]
      balls &lt;-<span class="st"> </span><span class="kw">c</span>(balls,ball) 
    }
  }
  <span class="kw">return</span>(balls)
}

rep_polyas_urn &lt;-<span class="st"> </span>function(N,alpha,R){
  out &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="kw">replicate</span>(R,<span class="kw">polyas_urn</span>(N,alpha)))
  <span class="kw">colnames</span>(out) &lt;-<span class="st"> </span><span class="dv">1</span>:R
  out %&gt;%
<span class="st">    </span><span class="kw">gather</span>(r,sample) %&gt;%
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">r=</span><span class="kw">as.factor</span>(r)) %&gt;%
<span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>sample,<span class="dt">y =</span> ..scaled..)) +<span class="st"> </span>
<span class="st">      </span><span class="kw">geom_density</span>(<span class="dt">colour=</span><span class="st">&quot;black&quot;</span>,<span class="dt">size=</span><span class="dv">1</span>,<span class="dt">fill=</span><span class="st">&quot;darkgreen&quot;</span>) +<span class="st"> </span>
<span class="st">      </span><span class="kw">facet_wrap</span>(~r) +<span class="st"> </span><span class="kw">xlim</span>(-<span class="dv">3</span>,<span class="dv">3</span>) +<span class="st"> </span><span class="kw">ylab</span>(<span class="st">&quot;&quot;</span>) +<span class="st"> </span><span class="kw">xlab</span>(<span class="st">&quot;&quot;</span>)
}

<span class="kw">rep_polyas_urn</span>(<span class="dv">25</span>,<span class="dv">500</span>,<span class="dv">12</span>)</code></pre></div>
<p><img src="12_machinelearning_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
</div>
<div id="stick-breaking" class="section level3">
<h3><span class="header-section-number">13.9.3</span> Stick Breaking</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">stick_breaking &lt;-<span class="st"> </span>function(N,alpha){
  p &lt;-<span class="st"> </span><span class="kw">rbeta</span>(N,<span class="dv">1</span>,alpha)
  len &lt;-<span class="st"> </span><span class="dv">1</span>
  w &lt;-<span class="st"> </span>p[<span class="dv">1</span>]
  for (i in <span class="dv">2</span>:N){
    len &lt;-<span class="st"> </span>len-w[i<span class="dv">-1</span>]
    w_new &lt;-<span class="st"> </span>p[i]*(len)
    w &lt;-<span class="st"> </span><span class="kw">c</span>(w,w_new)
  }
  <span class="kw">return</span>(w)
}

rep_stick_breaking &lt;-<span class="st"> </span>function(N,alpha,R){
  out &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="kw">replicate</span>(R,<span class="kw">stick_breaking</span>(N,alpha)),<span class="dv">1</span>:N)
  <span class="kw">colnames</span>(out) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>:R,<span class="st">&quot;Breaks&quot;</span>)
  out %&gt;%
<span class="st">    </span><span class="kw">gather</span>(r,Probability,-Breaks) %&gt;%
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">r=</span><span class="kw">as.factor</span>(r),<span class="dt">Breaks=</span><span class="kw">as.factor</span>(Breaks)) %&gt;%
<span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>Breaks,<span class="dt">y=</span>Probability,<span class="dt">ymin=</span><span class="dv">0</span>,<span class="dt">ymax=</span>Probability)) +
<span class="st">      </span><span class="kw">geom_linerange</span>(<span class="dt">colour=</span><span class="st">&quot;Blue&quot;</span>,<span class="dt">size=</span><span class="dv">1</span>) +
<span class="st">      </span><span class="kw">geom_point</span>(<span class="dt">colour=</span><span class="st">&quot;Blue&quot;</span>,<span class="dt">size=</span><span class="dv">4</span>) +
<span class="st">      </span><span class="kw">scale_y_continuous</span>(<span class="dt">lim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>)) +
<span class="st">      </span><span class="kw">facet_wrap</span>(~r) +
<span class="st">      </span><span class="kw">theme</span>(<span class="dt">panel.background =</span> <span class="kw">element_rect</span>(),
            <span class="dt">title=</span><span class="kw">element_text</span>(<span class="dt">size=</span><span class="dv">20</span>),
            <span class="dt">strip.text=</span><span class="kw">element_text</span>(<span class="dt">size=</span><span class="dv">13</span>),
            <span class="dt">axis.text=</span><span class="kw">element_text</span>(<span class="dt">size=</span><span class="dv">13</span>),
            <span class="dt">axis.title=</span><span class="kw">element_text</span>(<span class="dt">size=</span><span class="dv">18</span>,<span class="dt">face=</span><span class="st">&quot;bold&quot;</span>)) +
<span class="st">    </span><span class="kw">ggtitle</span>(<span class="kw">bquote</span>(alpha ==<span class="st"> </span>.(<span class="kw">paste</span>(alpha,<span class="dt">collapse=</span><span class="st">&quot; &quot;</span>))))
}

<span class="kw">rep_stick_breaking</span>(<span class="dv">10</span>,<span class="dv">1</span>,<span class="dv">12</span>)</code></pre></div>
<p><img src="12_machinelearning_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
</div>
</div>
<div id="iteratively-reweighted-least-squares" class="section level2">
<h2><span class="header-section-number">13.10</span> Iteratively Reweighted Least Squares</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">inv_logit &lt;-<span class="st"> </span>function(x) <span class="kw">return</span>(<span class="dv">1</span>/(<span class="dv">1</span>+<span class="kw">exp</span>(-x)))

N &lt;-<span class="st"> </span><span class="dv">100</span>
k &lt;-<span class="st"> </span><span class="dv">1</span>
X &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="dv">1</span>,<span class="kw">matrix</span>(<span class="kw">runif</span>(N*k,-<span class="dv">1</span>,<span class="dv">1</span>)))
theta_true &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(.<span class="dv">25</span>,-.<span class="dv">75</span>),<span class="dt">ncol=</span><span class="dv">1</span>)
y &lt;-<span class="st"> </span><span class="kw">rbinom</span>(N,<span class="dv">1</span>,<span class="kw">inv_logit</span>(X %*%<span class="st"> </span>theta_true))
<span class="kw">summary</span>(<span class="kw">glm</span>(y ~<span class="st"> </span>X[,-<span class="dv">1</span>], <span class="dt">family=</span><span class="kw">binomial</span>(<span class="dt">link=</span><span class="st">&quot;logit&quot;</span>)))</code></pre></div>
<pre><code>## 
## Call:
## glm(formula = y ~ X[, -1], family = binomial(link = &quot;logit&quot;))
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.7842  -1.2277   0.7490   0.9695   1.2757  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)   
## (Intercept)   0.5825     0.2153   2.705  0.00683 **
## X[, -1]      -0.8247     0.3847  -2.144  0.03206 * 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 131.79  on 99  degrees of freedom
## Residual deviance: 126.96  on 98  degrees of freedom
## AIC: 130.96
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">irls &lt;-<span class="st"> </span>function(X,y,<span class="dt">tol=</span><span class="fl">1e-6</span>){
  k &lt;-<span class="st"> </span><span class="kw">ncol</span>(X)
  N &lt;-<span class="st"> </span><span class="kw">nrow</span>(X)
  theta &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rep</span>(<span class="dv">0</span>,k),<span class="dt">ncol=</span><span class="dv">1</span>)
  theta_new &lt;-<span class="st"> </span><span class="ot">Inf</span>
  
  while (<span class="kw">max</span>(<span class="kw">abs</span>(theta -<span class="st"> </span>theta_new)) &gt;<span class="st"> </span>tol){
    a &lt;-<span class="st"> </span>X %*%<span class="st"> </span>theta
    p &lt;-<span class="st"> </span><span class="kw">inv_logit</span>(a)
    s &lt;-<span class="st"> </span><span class="kw">diag</span>(<span class="kw">c</span>(p*(<span class="dv">1</span>-p)),N,N)
    xsx &lt;-<span class="st"> </span><span class="kw">t</span>(X) %*%<span class="st"> </span>s %*%<span class="st"> </span>X
    sxt &lt;-<span class="st"> </span>s %*%<span class="st"> </span>X %*%<span class="st"> </span>theta
    
    theta_new &lt;-<span class="st"> </span>theta
    theta &lt;-<span class="st"> </span><span class="kw">solve</span>(xsx) %*%<span class="st"> </span><span class="kw">t</span>(X) %*%<span class="st"> </span>(sxt +<span class="st"> </span>y -<span class="st"> </span>p)
  }
  <span class="kw">return</span>(theta)
}</code></pre></div>
</div>
<div id="neural-network" class="section level2">
<h2><span class="header-section-number">13.11</span> Neural Network</h2>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> numpy <span class="im">as</span> np
<span class="im">import</span> random
<span class="im">import</span> cPickle
<span class="im">import</span> gzip
<span class="im">import</span> os
<span class="im">import</span> sys

<span class="kw">def</span> load_data():
    f <span class="op">=</span> gzip.<span class="bu">open</span>(<span class="st">&#39;mnist.pkl.gz&#39;</span>, <span class="st">&#39;rb&#39;</span>)
    training_data, validation_data, test_data <span class="op">=</span> cPickle.load(f)
    f.close()
    <span class="cf">return</span> (training_data, validation_data, test_data)
    
<span class="kw">def</span> load_data_wrapper():
    tr_d, va_d, te_d <span class="op">=</span> load_data()
    training_inputs <span class="op">=</span> [np.reshape(x, (<span class="dv">784</span>, <span class="dv">1</span>)) <span class="cf">for</span> x <span class="op">in</span> tr_d[<span class="dv">0</span>]]
    training_results <span class="op">=</span> [vectorized_result(y) <span class="cf">for</span> y <span class="op">in</span> tr_d[<span class="dv">1</span>]]
    training_data <span class="op">=</span> <span class="bu">zip</span>(training_inputs, training_results)
    validation_inputs <span class="op">=</span> [np.reshape(x, (<span class="dv">784</span>, <span class="dv">1</span>)) <span class="cf">for</span> x <span class="op">in</span> va_d[<span class="dv">0</span>]]
    validation_data <span class="op">=</span> <span class="bu">zip</span>(validation_inputs, va_d[<span class="dv">1</span>])
    test_inputs <span class="op">=</span> [np.reshape(x, (<span class="dv">784</span>, <span class="dv">1</span>)) <span class="cf">for</span> x <span class="op">in</span> te_d[<span class="dv">0</span>]]
    test_data <span class="op">=</span> <span class="bu">zip</span>(test_inputs, te_d[<span class="dv">1</span>])
    <span class="cf">return</span> (training_data, validation_data, test_data)
    
<span class="kw">def</span> vectorized_result(j):
    e <span class="op">=</span> np.zeros((<span class="dv">10</span>, <span class="dv">1</span>))
    e[j] <span class="op">=</span> <span class="fl">1.0</span>
    <span class="cf">return</span> e
    
<span class="kw">def</span> sigmoid(z):
    <span class="cf">return</span> <span class="fl">1.0</span><span class="op">/</span>(<span class="fl">1.0</span><span class="op">+</span>np.exp(<span class="op">-</span>z))
    
<span class="kw">def</span> sigmoid_prime(z):
    <span class="cf">return</span> sigmoid(z)<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>sigmoid(z))

training_data, validation_data, test_data <span class="op">=</span> load_data_wrapper()

sizes <span class="op">=</span> [<span class="dv">784</span>, <span class="dv">30</span>, <span class="dv">10</span>]
num_layers <span class="op">=</span> <span class="bu">len</span>(sizes)
eta <span class="op">=</span> <span class="fl">3.0</span> <span class="co"># must be real, not integer (so not 3)</span>
epochs <span class="op">=</span> <span class="dv">30</span>
n <span class="op">=</span> <span class="bu">len</span>(training_data)
n_test <span class="op">=</span> <span class="bu">len</span>(test_data)
mini_batch_size <span class="op">=</span> <span class="dv">10</span>

biases <span class="op">=</span> [np.zeros((y, <span class="dv">1</span>)) <span class="cf">for</span> y <span class="op">in</span> sizes[<span class="dv">1</span>:]]
weights <span class="op">=</span> [np.random.randn(y, x) <span class="cf">for</span> x, y <span class="op">in</span> <span class="bu">zip</span>(sizes[:<span class="op">-</span><span class="dv">1</span>], sizes[<span class="dv">1</span>:])]
<span class="cf">for</span> j <span class="op">in</span> <span class="bu">xrange</span>(epochs):
    
        random.shuffle(training_data)
        mini_batches <span class="op">=</span> [training_data[k:k<span class="op">+</span>mini_batch_size] <span class="cf">for</span> k <span class="op">in</span> <span class="bu">xrange</span>(<span class="dv">0</span>, n, mini_batch_size)] <span class="co"># n/mini_batch_size</span>
        <span class="co"># mini_batches is the result of breaking the training_data into length 25 batches, so 2000 mini_batches</span>
<span class="cf">for</span> mini_batch <span class="op">in</span> mini_batches:
        
            <span class="co"># start gradient at 0</span>
            nabla_b <span class="op">=</span> [np.zeros(b.shape) <span class="cf">for</span> b <span class="op">in</span> biases]
            nabla_w <span class="op">=</span> [np.zeros(w.shape) <span class="cf">for</span> w <span class="op">in</span> weights]
    
            <span class="cf">for</span> x, y <span class="op">in</span> mini_batch:
delta_nabla_b <span class="op">=</span> [np.zeros(b.shape) <span class="cf">for</span> b <span class="op">in</span> biases]
                delta_nabla_w <span class="op">=</span> [np.zeros(w.shape) <span class="cf">for</span> w <span class="op">in</span> weights]
<span class="co"># forward pass</span>
                activation <span class="op">=</span> x
                activations <span class="op">=</span> [x] <span class="co"># list to store all the activations, layer by layer</span>
                zs <span class="op">=</span> [] <span class="co"># list to store all the z vectors, layer by layer</span>
<span class="cf">for</span> b, w <span class="op">in</span> <span class="bu">zip</span>(biases, weights):
                    z <span class="op">=</span> np.dot(w, activation) <span class="op">+</span> b
                    zs.append(z)
                    activation <span class="op">=</span> sigmoid(z)
                    activations.append(activation)
                <span class="co"># dot product between w1 in layer 1-2 with activation=input, add b1 for layer 2, set output as activation1</span>
                <span class="co"># dot product between w2 in layer 2-3 with activation=activation1, add b2 for layer 3, set output as activation2</span>
<span class="co"># backward pass</span>
                delta <span class="op">=</span> (activations[<span class="op">-</span><span class="dv">1</span>]<span class="op">-</span>y) <span class="op">*</span> sigmoid_prime(zs[<span class="op">-</span><span class="dv">1</span>]) <span class="co"># dC/dz_lj = (a - y) * o&#39;(z), cost wrt output layer</span>
                delta_nabla_b[<span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> delta <span class="co"># dC/db_lj = delta_lj</span>
                delta_nabla_w[<span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> np.dot(delta, activations[<span class="op">-</span><span class="dv">2</span>].transpose()) <span class="co"># dC/dw_ljk = a_(l-1)k * delta_lj</span>
<span class="cf">for</span> l <span class="op">in</span> <span class="bu">xrange</span>(<span class="dv">2</span>, num_layers):
                    delta <span class="op">=</span> np.dot(weights[<span class="op">-</span>l<span class="dv">+1</span>].transpose(), delta) <span class="op">*</span> sigmoid_prime(zs[<span class="op">-</span>l]) <span class="co"># dC/dz_lj</span>
                    delta_nabla_b[<span class="op">-</span>l] <span class="op">=</span> delta <span class="co"># dC/db_lj</span>
                    delta_nabla_w[<span class="op">-</span>l] <span class="op">=</span> np.dot(delta, activations[<span class="op">-</span>l<span class="dv">-1</span>].transpose()) <span class="co"># dC/dw_ljk</span>
nabla_b <span class="op">=</span> [nb<span class="op">+</span>dnb <span class="cf">for</span> nb, dnb <span class="op">in</span> <span class="bu">zip</span>(nabla_b, delta_nabla_b)]
                nabla_w <span class="op">=</span> [nw<span class="op">+</span>dnw <span class="cf">for</span> nw, dnw <span class="op">in</span> <span class="bu">zip</span>(nabla_w, delta_nabla_w)]
biases <span class="op">=</span> [b<span class="op">-</span>(eta<span class="op">/</span><span class="bu">len</span>(mini_batch))<span class="op">*</span>nb <span class="cf">for</span> b, nb <span class="op">in</span> <span class="bu">zip</span>(biases, nabla_b)]
            weights <span class="op">=</span> [w<span class="op">-</span>(eta<span class="op">/</span><span class="bu">len</span>(mini_batch))<span class="op">*</span>nw <span class="cf">for</span> w, nw <span class="op">in</span> <span class="bu">zip</span>(weights, nabla_w)]
test_results <span class="op">=</span> [(np.argmax(feedforward(x,biases,weights)), y) <span class="cf">for</span> (x, y) <span class="op">in</span> test_data]
        test_results <span class="op">=</span> <span class="bu">sum</span>(<span class="bu">int</span>(x <span class="op">==</span> y) <span class="cf">for</span> (x, y) <span class="op">in</span> test_results)
        
        <span class="bu">print</span> <span class="st">&quot;Epoch </span><span class="sc">{0}</span><span class="st">: </span><span class="sc">{1}</span><span class="st"> / </span><span class="sc">{2}</span><span class="st"> | mean_w = </span><span class="sc">{3}</span><span class="st"> | mean_nabla_w = </span><span class="sc">{4}</span><span class="st">&quot;</span>.<span class="bu">format</span>(j, test_results, n_test,np.mean(weights[<span class="dv">1</span>]),np.mean(nabla_w[<span class="dv">1</span>]))</code></pre></div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="tm.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bioinformatics.pdf"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
